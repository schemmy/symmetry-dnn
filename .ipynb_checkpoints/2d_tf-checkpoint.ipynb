{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='2'\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\npgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1187d5208>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "random.seed(3)\n",
    "\n",
    "def rand_cluster(n,c,r):\n",
    "    \"\"\"returns n random points in disk of radius r centered at c\"\"\"\n",
    "    x,y = c\n",
    "    points = []\n",
    "    for i in range(n):\n",
    "        theta = 2*math.pi*random.random()\n",
    "        s = r*random.random()\n",
    "        points.append((x+s*math.cos(theta), y+s*math.sin(theta)))\n",
    "    return points\n",
    "\n",
    "def rand_clusters(k,n,r, a,b,c,d):\n",
    "    \"\"\"return k clusters of n points each in random disks of radius r\n",
    "    where the centers of the disk are chosen randomly in [a,b]x[c,d]\"\"\"\n",
    "    clusters = []\n",
    "    for _ in range(k):\n",
    "        x = a + (b-a)*random.random()\n",
    "        y = c + (d-c)*random.random()\n",
    "        clusters.extend(rand_cluster(n,(x,y),r))\n",
    "    return clusters\n",
    "\n",
    "n = 50\n",
    "X = rand_clusters(2,50,1.8,-1,1,-1,1)\n",
    "data = np.array(X)\n",
    "label = np.transpose(np.array([[1]*n + [0]*n, [0]*n + [1]*n]))\n",
    "# label = np.array([1]*n + [0]*n)\n",
    "# print (data, label)\n",
    "\n",
    "plt.scatter(data[:n,0], data[:n,1], color=['red'])\n",
    "plt.scatter(data[n:,0], data[n:,1], color=['green'])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "def weight_variable(shape, name):\n",
    "    initial = tf.truncated_normal(shape=shape, stddev=0.1)\n",
    "    return tf.get_variable(name=name, initializer=initial)\n",
    "\n",
    "def bias_variable(shape, name):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.get_variable(name=name, initializer=initial)\n",
    "\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, 2])\n",
    "y_ = tf.placeholder(tf.float32, [None, 2])\n",
    "\n",
    "#hidden layer\n",
    "# W_fc1 = weight_variable([2, 4], 'W1')\n",
    "# b_fc1 = bias_variable([4], 'b1')\n",
    "# h_fc1 = tf.sigmoid(tf.matmul(x, W_fc1) + b_fc1)\n",
    "# #output layer\n",
    "# W_fc2 = weight_variable([4, 2], 'W2')\n",
    "# b_fc2 = bias_variable([2], 'b2')\n",
    "# y = tf.sigmoid(tf.matmul(h_fc1, W_fc2) + b_fc2)\n",
    "\n",
    "n_input = 2\n",
    "n_hidden = 4\n",
    "n_hidden2 = 5\n",
    "n_output = 2\n",
    "lmd = 1e-4\n",
    "# parameters = tf.Variable(tf.concat([tf.truncated_normal([n_input * n_hidden]), tf.zeros([n_hidden]),\\\n",
    "                            # tf.truncated_normal([n_hidden * n_output]), tf.zeros([n_output])],0))\n",
    "parameters = tf.Variable(tf.concat([tf.truncated_normal([n_input * n_hidden]), tf.zeros([n_hidden]),\\\n",
    "#                                     tf.truncated_normal([n_hidden * n_hidden2]), tf.zeros([n_hidden2]),\\\n",
    "                                    tf.truncated_normal([n_hidden * n_output]), tf.zeros([n_output]),\\\n",
    "                                   ], 0))\n",
    "\n",
    "idx_from = 0 \n",
    "weights1 = tf.reshape(tf.slice(parameters, begin=[idx_from], size=[n_input*n_hidden]), [n_input, n_hidden])\n",
    "idx_from = idx_from + n_input*n_hidden\n",
    "biases1 = tf.reshape(tf.slice(parameters, begin=[idx_from], size=[n_hidden]), [n_hidden])\n",
    "hidden = tf.sigmoid(tf.matmul(x, weights1) + biases1)\n",
    "\n",
    "idx_from = idx_from + n_hidden\n",
    "weights2 = tf.reshape(tf.slice(parameters, begin=[idx_from], size=[n_hidden*n_output]), [n_hidden, n_output])\n",
    "idx_from = idx_from + n_hidden*n_output\n",
    "biases2 = tf.reshape(tf.slice(parameters, begin=[idx_from], size=[n_output]), [n_output])\n",
    "y = tf.nn.sigmoid(tf.matmul(hidden, weights2) + biases2)\n",
    "\n",
    "# idx_from = idx_from + n_hidden\n",
    "# weights2 = tf.reshape(tf.slice(parameters, begin=[idx_from], size=[n_hidden*n_hidden2]), [n_hidden, n_hidden2])\n",
    "# idx_from = idx_from + n_hidden*n_hidden2\n",
    "# biases2 = tf.reshape(tf.slice(parameters, begin=[idx_from], size=[n_hidden2]), [n_hidden2])\n",
    "# hidden2 = tf.sigmoid(tf.matmul(hidden, weights2) + biases2)\n",
    "\n",
    "# idx_from = idx_from + n_hidden2\n",
    "# weights3 = tf.reshape(tf.slice(parameters, begin=[idx_from], size=[n_hidden2*n_output]), [n_hidden2, n_output])\n",
    "# idx_from = idx_from + n_hidden2*n_output\n",
    "# biases3 = tf.reshape(tf.slice(parameters, begin=[idx_from], size=[n_output]), [n_output])\n",
    "# y = tf.nn.sigmoid(tf.matmul(hidden2, weights3) + biases3)\n",
    "\n",
    "weights = tf.concat([tf.reshape(weights1, [-1]), tf.reshape(weights2, [-1])], 0)\n",
    "regularizer = tf.nn.l2_loss(weights)\n",
    "\n",
    "los = tf.reduce_mean(tf.reduce_sum(tf.pow(y_ - y, 2), reduction_indices=[1])) #I also tried simply tf.nn.l2_loss(y_ - y)\n",
    "loss = los + lmd * regularizer\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(1e-2)\n",
    "grads_and_vars = optimizer.compute_gradients(loss)\n",
    "hess = tf.hessians(loss, parameters)\n",
    "train_step = optimizer.apply_gradients(grads_and_vars)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_accuracy():\n",
    "    correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    return sess.run(accuracy, feed_dict={x: data, y_: label})\n",
    "\n",
    "def get_norm_grad():\n",
    "    nng = 0.\n",
    "    for gv in grads_and_vars:\n",
    "        # print(str(sess.run(gv[0], feed_dict={x: data, y_: label})) + \" - \" + gv[1].name)\n",
    "        grad = sess.run(gv[0], feed_dict={x: data, y_: label})\n",
    "        nng += np.linalg.norm(grad[0]) ** 2\n",
    "    return np.sqrt(nng)\n",
    "\n",
    "def display(w):\n",
    "\n",
    "    idx_from = 0 \n",
    "    weights1 = np.reshape(w[idx_from: n_input*n_hidden], [n_input, n_hidden])\n",
    "    idx_from = idx_from + n_input*n_hidden\n",
    "    biases1 = np.reshape(w[idx_from: idx_from+n_hidden], [n_hidden])\n",
    "    idx_from = idx_from + n_hidden\n",
    "    weights2 = np.reshape(w[idx_from: idx_from+n_hidden*n_output], [n_hidden, n_output])\n",
    "    idx_from = idx_from + n_hidden*n_output\n",
    "    biases2 = np.reshape(w[idx_from: idx_from+n_output], [n_output])\n",
    "    print (weights1)\n",
    "    print (biases1)\n",
    "    print (weights2)\n",
    "    print (biases2)\n",
    "    \n",
    "     \n",
    "def displayH(a):\n",
    "    a = np.array(a[0])\n",
    "#     print (\"Matrix[\"+(\"%d\" %a.shape[0])+\"][\"+(\"%d\" %a.shape[1])+\"]\")\n",
    "    rows = a.shape[0]\n",
    "    cols = a.shape[1]\n",
    "    for i in range(0, rows):\n",
    "        for j in range(0, cols):\n",
    "            print(\"%0.2g \" %a[i,j], end=\"\")\n",
    "        print ()\n",
    "    print ()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 239, accuracy 76.00%, loss 0.320315, nng 9.604e-09, nnw 14.59, high_eig 0.1045, low_eig 7.254e-14.\n",
      "Epoch 169, accuracy 76.00%, loss 0.351368, nng 8.277e-09, nnw 8.203, high_eig 0.09372, low_eig -9.204e-13.\n",
      "Epoch 190, accuracy 76.00%, loss 0.342640, nng 3.776e-09, nnw 7.778, high_eig 0.156, low_eig 3.987e-12.\n",
      "Epoch 207, accuracy 77.00%, loss 0.320345, nng 7.135e-09, nnw 14.63, high_eig 0.1054, low_eig -4.172e-09.\n",
      "Epoch 192, accuracy 75.00%, loss 0.346984, nng 4.143e-09, nnw 8.537, high_eig 0.08386, low_eig -4.931e-12.\n",
      "Epoch 168, accuracy 78.00%, loss 0.336357, nng 6.228e-09, nnw 7.768, high_eig 0.08369, low_eig -1.204e-08.\n",
      "Epoch 213, accuracy 78.00%, loss 0.340902, nng 9.313e-10, nnw 5.781, high_eig 0.08985, low_eig -3.004e-10.\n",
      "Epoch 155, accuracy 75.00%, loss 0.330497, nng 5.466e-09, nnw 12.43, high_eig 0.09789, low_eig -1.428e-06.\n",
      "Epoch 265, accuracy 78.00%, loss 0.340901, nng 3.9e-09, nnw 5.781, high_eig 0.08985, low_eig -6.05e-15.\n",
      "Epoch 202, accuracy 76.00%, loss 0.351373, nng 4.366e-09, nnw 8.202, high_eig 0.0937, low_eig -5.146e-09.\n"
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "\n",
    "dic = {}\n",
    "for _ in range(10):\n",
    "\n",
    "    tf.global_variables_initializer().run()\n",
    "    flag = 0\n",
    "    for i in range(1000):\n",
    "        sess.run(train_step, feed_dict={x: data, y_: label})\n",
    "        nng = get_norm_grad()\n",
    "        if nng < 1e-8:\n",
    "            flag = 1\n",
    "            break\n",
    "\n",
    "    if flag == 1:\n",
    "        v, H, w = sess.run([loss, hess, parameters], feed_dict={x: data, y_: label})    \n",
    "        eigs = sorted(np.linalg.eigvals(H)[0])\n",
    "        print(\"Epoch {}, accuracy {:.2f}%, loss {:.6f}, nng {:.4g}, nnw {:.4g}, high_eig {:.4g}, low_eig {:.4g}.\"\\\n",
    "                    .format(i+1, get_accuracy()*100, v, nng, np.linalg.norm(w[:n_hidden]), max(eigs), min(eigs) ))\n",
    "#         display(w)\n",
    "#         displayH(H)\n",
    "        dic[int(v * 1e5)] = dic.get(int(v * 1e5), []) + [(min(eigs), w)]\n",
    "sess.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for key in sorted(dic):\n",
    "    print (\"%s:\" % (key))\n",
    "    for e, v in dic[key]:\n",
    "        print (e)\n",
    "        display(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w0 = np.array([10,0,0,0,1,0,0,0, \n",
    "              0,0,0,0,\n",
    "              0,0,0,0,0,0,0,0, \n",
    "              0,0])\n",
    "private_init = parameters.assign(w0)\n",
    "\n",
    "idx = [1,2,3,5,6,7,\n",
    "            9,10,11] + \\\n",
    "            list(range(14,20))\n",
    "fix_coordinate = []\n",
    "for i in idx:\n",
    "    fix_coordinate.append(parameters[i].assign(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 204, accuracy 75.00%, loss 0.353688, nng 6.461e-09, nnw 6.138, high_eig 0.1378, low_eig -0.001555.\n",
      "[[ 6.1384387   0.          0.          0.        ]\n",
      " [ 3.85529733  0.          0.          0.        ]]\n",
      "[ 0.0328644  0.         0.         0.       ]\n",
      "[[-3.14847136  3.14847159]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]]\n",
      "[ 1.25850093 -1.25850058]\n",
      "Epoch 256, accuracy 75.00%, loss 0.330258, nng 2.619e-10, nnw 12.53, high_eig 0.1263+0j, low_eig -0.001666+0j.\n",
      "[[  4.52024651 -11.69125748   0.           0.        ]\n",
      " [  6.80131388   3.50514174   0.           0.        ]]\n",
      "[ 0.87811577 -5.12807369  0.          0.        ]\n",
      "[[-2.50723052  2.50723052]\n",
      " [ 2.15404177 -2.15404272]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]]\n",
      "[ 0.3379378  -0.33793768]\n",
      "Epoch 171, accuracy 75.00%, loss 0.330258, nng 5.093e-09, nnw 12.53, high_eig 0.1119, low_eig -0.001501.\n",
      "[[  4.52028894e+00  -1.16912632e+01   2.49887467e-04   0.00000000e+00]\n",
      " [  6.80136728e+00   3.50522685e+00  -8.83873668e-04   0.00000000e+00]]\n",
      "[  0.87811351  -5.128088   -15.73108006   0.        ]\n",
      "[[ -2.50726461e+00   2.50718856e+00]\n",
      " [  2.15400386e+00  -2.15406132e+00]\n",
      " [ -1.24359518e-04   4.06605104e-04]\n",
      " [  0.00000000e+00   0.00000000e+00]]\n",
      "[ 0.33794069 -0.33793011]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "dic = {}\n",
    "for _ in range(1):\n",
    "\n",
    "    tf.global_variables_initializer().run()\n",
    "    sess.run(private_init)    \n",
    "    flag = 0\n",
    "    for i in range(1000):\n",
    "        sess.run(train_step, feed_dict={x: data, y_: label})\n",
    "        for op in fix_coordinate:\n",
    "            sess.run(op)\n",
    "        nng = get_norm_grad()\n",
    "        if nng < 1e-8:\n",
    "            flag = 1\n",
    "            break\n",
    "\n",
    "    if flag == 1:\n",
    "        v, H, w = sess.run([loss, hess, parameters], feed_dict={x: data, y_: label})    \n",
    "        eigs = sorted(np.linalg.eigvals(H)[0])\n",
    "        print(\"Epoch {}, accuracy {:.2f}%, loss {:.6f}, nng {:.4g}, nnw {:.4g}, high_eig {:.4g}, low_eig {:.4g}.\"\\\n",
    "                    .format(i+1, get_accuracy()*100, v, nng, np.linalg.norm(w[:n_hidden]), max(eigs), min(eigs) ))\n",
    "        display(w)\n",
    "#         displayH(H)\n",
    "#         dic[int(v * 1e5)] = dic.get(int(v * 1e5), []) + [(min(eigs), w)]\n",
    "    \n",
    "    \n",
    "    idx = [2,3,6,7,\n",
    "            10,11] + \\\n",
    "            list(range(16,20))\n",
    "    fix_coordinate2 = []\n",
    "    for i in idx:\n",
    "        fix_coordinate2.append(parameters[i].assign(0))\n",
    "    flag = 0\n",
    "    sess.run(parameters[1].assign(1.))\n",
    "    for i in range(1000):\n",
    "        sess.run(train_step, feed_dict={x: data, y_: label})\n",
    "        for op in fix_coordinate2:\n",
    "            sess.run(op)\n",
    "        nng = get_norm_grad()\n",
    "        if nng < 1e-8:\n",
    "            flag = 1\n",
    "            break\n",
    "\n",
    "    if flag == 1:\n",
    "        v, H, w = sess.run([loss, hess, parameters], feed_dict={x: data, y_: label})    \n",
    "        eigs = sorted(np.linalg.eigvals(H)[0])\n",
    "        print(\"Epoch {}, accuracy {:.2f}%, loss {:.6f}, nng {:.4g}, nnw {:.4g}, high_eig {:.4g}, low_eig {:.4g}.\"\\\n",
    "                    .format(i+1, get_accuracy()*100, v, nng, np.linalg.norm(w[:n_hidden]), max(eigs), min(eigs) ))\n",
    "        display(w)\n",
    "        \n",
    "    idx = [3,7,\n",
    "            11] + \\\n",
    "            list(range(18,20))\n",
    "    fix_coordinate2 = []\n",
    "    for i in idx:\n",
    "        fix_coordinate2.append(parameters[i].assign(0))\n",
    "    flag = 1\n",
    "    sess.run(parameters[17].assign(.5))\n",
    "    for i in range(1000):\n",
    "        sess.run(train_step, feed_dict={x: data, y_: label})\n",
    "        for op in fix_coordinate2:\n",
    "            sess.run(op)\n",
    "        nng = get_norm_grad()\n",
    "        if nng < 1e-8:\n",
    "            flag = 1\n",
    "            break\n",
    "\n",
    "    if flag == 1:\n",
    "        v, H, w = sess.run([loss, hess, parameters], feed_dict={x: data, y_: label})    \n",
    "        eigs = sorted(np.linalg.eigvals(H)[0])\n",
    "        print(\"Epoch {}, accuracy {:.2f}%, loss {:.6f}, nng {:.4g}, nnw {:.4g}, high_eig {:.4g}, low_eig {:.4g}.\"\\\n",
    "                    .format(i+1, get_accuracy()*100, v, nng, np.linalg.norm(w[:n_hidden]), max(eigs), min(eigs) ))\n",
    "        display(w)\n",
    "         \n",
    "sess.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, accuracy 50.00%, loss 0.625679, nng 0.004765, nnw 0.8299, high_eig 0.2126, low_eig -0.05732.\n",
      "Epoch 21, accuracy 50.00%, loss 0.600658, nng 0.007318, nnw 2.251, high_eig 0.07375, low_eig -0.03436.\n",
      "Epoch 41, accuracy 63.00%, loss 0.429007, nng 0.003337, nnw 3.667, high_eig 0.1714, low_eig -0.01519.\n",
      "Epoch 61, accuracy 57.00%, loss 0.543411, nng 0.009433, nnw 4.085, high_eig 0.04797, low_eig -0.02954.\n",
      "Epoch 81, accuracy 72.00%, loss 0.396691, nng 0.001797, nnw 5.956, high_eig 0.1372, low_eig -0.01529.\n",
      "Epoch 101, accuracy 76.00%, loss 0.365153, nng 0.003711, nnw 6.227, high_eig 0.1048, low_eig -0.004971.\n",
      "Epoch 121, accuracy 74.00%, loss 0.400726, nng 0.001657, nnw 6.918, high_eig 0.09261, low_eig -0.0104.\n",
      "Epoch 141, accuracy 75.00%, loss 0.365882, nng 0.002463, nnw 7.466, high_eig 0.09342, low_eig -0.005233.\n",
      "Epoch 161, accuracy 74.00%, loss 0.362012, nng 0.001687, nnw 7.01, high_eig 0.105, low_eig -0.003657.\n",
      "Epoch 181, accuracy 76.00%, loss 0.359446, nng 0.0004084, nnw 7.136, high_eig 0.1097, low_eig -0.001281.\n",
      "Epoch 201, accuracy 75.00%, loss 0.361163, nng 0.0002107, nnw 7.473, high_eig 0.1083, low_eig -0.003534.\n",
      "Epoch 221, accuracy 76.00%, loss 0.363080, nng 0.001232, nnw 7.559, high_eig 0.08472, low_eig -0.003205.\n",
      "Epoch 241, accuracy 76.00%, loss 0.374499, nng 0.00138, nnw 7.487, high_eig 0.08976, low_eig -0.005568.\n",
      "Epoch 261, accuracy 76.00%, loss 0.360159, nng 0.002337, nnw 7.434, high_eig 0.09835, low_eig -0.002419.\n",
      "Epoch 281, accuracy 71.00%, loss 0.408487, nng 0.0006755, nnw 8.195, high_eig 0.1097, low_eig -0.01504.\n",
      "Epoch 301, accuracy 77.00%, loss 0.366523, nng 0.0008857, nnw 8.42, high_eig 0.1016, low_eig -0.005438.\n",
      "Epoch 321, accuracy 74.00%, loss 0.360377, nng 0.0008776, nnw 8.346, high_eig 0.08582, low_eig -0.003327.\n",
      "Epoch 341, accuracy 76.00%, loss 0.362271, nng 0.00276, nnw 7.869, high_eig 0.09593, low_eig -0.004547.\n",
      "Epoch 361, accuracy 63.00%, loss 0.460266, nng 0.003402, nnw 7.922, high_eig 0.09185, low_eig -0.01413.\n",
      "Epoch 381, accuracy 73.00%, loss 0.391981, nng 0.001895, nnw 8.122, high_eig 0.1057, low_eig -0.008205.\n",
      "Epoch 401, accuracy 76.00%, loss 0.369772, nng 0.002597, nnw 7.603, high_eig 0.09778, low_eig -0.005829.\n",
      "Epoch 421, accuracy 73.00%, loss 0.360757, nng 0.00228, nnw 8.107, high_eig 0.09567, low_eig -0.002996.\n",
      "Epoch 441, accuracy 72.00%, loss 0.415727, nng 0.002369, nnw 7.991, high_eig 0.09231, low_eig -0.01137.\n",
      "Epoch 461, accuracy 70.00%, loss 0.421836, nng 0.002629, nnw 7.831, high_eig 0.09024, low_eig -0.01222.\n",
      "Epoch 481, accuracy 75.00%, loss 0.364810, nng 0.002836, nnw 7.81, high_eig 0.08325, low_eig -0.005665.\n",
      "Epoch 501, accuracy 77.00%, loss 0.362966, nng 0.00127, nnw 8.128, high_eig 0.09551, low_eig -0.003218.\n",
      "Epoch 521, accuracy 76.00%, loss 0.361872, nng 0.001987, nnw 7.833, high_eig 0.1045, low_eig -0.002497.\n",
      "Epoch 541, accuracy 74.00%, loss 0.395020, nng 0.000936, nnw 8.453, high_eig 0.1186, low_eig -0.01072.\n",
      "Epoch 561, accuracy 77.00%, loss 0.361562, nng 0.001402, nnw 8.841, high_eig 0.06876, low_eig -0.002046.\n",
      "Epoch 581, accuracy 76.00%, loss 0.359793, nng 8.978e-05, nnw 8.793, high_eig 0.0707, low_eig -0.001607.\n",
      "Epoch 601, accuracy 75.00%, loss 0.363325, nng 0.002803, nnw 8.441, high_eig 0.07526, low_eig -0.003406.\n",
      "Epoch 621, accuracy 75.00%, loss 0.357529, nng 0.0005736, nnw 8.842, high_eig 0.08475, low_eig -0.001221.\n",
      "Epoch 641, accuracy 74.00%, loss 0.402300, nng 0.001292, nnw 8.596, high_eig 0.09644, low_eig -0.008281.\n",
      "Epoch 661, accuracy 74.00%, loss 0.357998, nng 0.0004146, nnw 8.952, high_eig 0.09284, low_eig -0.002448.\n",
      "Epoch 681, accuracy 76.00%, loss 0.366019, nng 0.001316, nnw 9.243, high_eig 0.105, low_eig -0.004752.\n",
      "Epoch 701, accuracy 75.00%, loss 0.357074, nng 0.0005201, nnw 9.109, high_eig 0.07711, low_eig -0.001544.\n",
      "Epoch 721, accuracy 75.00%, loss 0.360248, nng 0.003315, nnw 8.593, high_eig 0.07632, low_eig -0.001992.\n",
      "Epoch 741, accuracy 75.00%, loss 0.361906, nng 0.0007455, nnw 9.175, high_eig 0.07933, low_eig -0.003367.\n",
      "Epoch 761, accuracy 74.00%, loss 0.394399, nng 0.0006321, nnw 9.474, high_eig 0.1195, low_eig -0.01045.\n",
      "Epoch 781, accuracy 72.00%, loss 0.405809, nng 0.003449, nnw 9.657, high_eig 0.08596, low_eig -0.007561.\n",
      "Epoch 801, accuracy 76.00%, loss 0.380506, nng 0.002082, nnw 9.165, high_eig 0.08175, low_eig -0.005722.\n",
      "Epoch 821, accuracy 74.00%, loss 0.360995, nng 0.001716, nnw 9.452, high_eig 0.06189, low_eig -0.001827.\n",
      "Epoch 841, accuracy 74.00%, loss 0.379037, nng 0.003179, nnw 9.747, high_eig 0.07036, low_eig -0.005387.\n",
      "Epoch 861, accuracy 77.00%, loss 0.367704, nng 0.0002837, nnw 9.694, high_eig 0.07688, low_eig -0.005158.\n",
      "Epoch 881, accuracy 77.00%, loss 0.375448, nng 0.002592, nnw 9.332, high_eig 0.07961, low_eig -0.006761.\n",
      "Epoch 901, accuracy 74.00%, loss 0.379342, nng 0.003093, nnw 9.934, high_eig 0.0711, low_eig -0.005339.\n",
      "Epoch 921, accuracy 75.00%, loss 0.360902, nng 0.0006421, nnw 9.936, high_eig 0.05953, low_eig -0.001659.\n",
      "Epoch 941, accuracy 76.00%, loss 0.365640, nng 0.00371, nnw 9.185, high_eig 0.07428, low_eig -0.004433.\n",
      "Epoch 961, accuracy 74.00%, loss 0.387056, nng 0.001056, nnw 9.828, high_eig 0.09165, low_eig -0.009722.\n",
      "Epoch 981, accuracy 77.00%, loss 0.362771, nng 0.0001463, nnw 10.11, high_eig 0.08698, low_eig -0.004524.\n",
      "Epoch 1000, accuracy 77.00%, loss 0.365717, nng 0.0001463, nnw 10.03, high_eig 0.07737, low_eig -0.003641.\n",
      "[[ 7.40890074  2.10273361 -3.68977451  5.25928211]\n",
      " [ 4.13543224  1.52993047 -4.42800283  3.15226817]]\n",
      "[-0.24070421 -3.02293086 -1.90258992 -0.65674561]\n",
      "[[-2.22592354  2.12277699]\n",
      " [ 0.46640623 -0.32875034]\n",
      " [ 0.95597291 -1.25627124]\n",
      " [-1.25882292  1.06046128]]\n",
      "[ 0.3858079 -0.1894109]\n"
     ]
    }
   ],
   "source": [
    "w0 = np.array([1,0,0,0,0,0,0,0, \n",
    "              .3,0,0,0,\n",
    "              0,0,0,0,0,0,0,0, \n",
    "              0,0])\n",
    "w0 = np.array([0.5]*22)\n",
    "private_init = parameters.assign(w0)\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "dic = {}\n",
    "for _ in range(1):\n",
    "\n",
    "    tf.global_variables_initializer().run()\n",
    "#     sess.run(private_init)    \n",
    "    flag = 1\n",
    "    for i in range(1000):\n",
    "        idx = random.randint(0, 9)\n",
    "        sess.run(train_step, feed_dict={x: data[idx*10: (idx+1)*10], y_: label[idx*10: (idx+1)*10]})\n",
    "        \n",
    "        if i % 20 == 0:\n",
    "            v, H, w = sess.run([loss, hess, parameters], feed_dict={x: data, y_: label})    \n",
    "            nng = get_norm_grad()\n",
    "            eigs = sorted(np.linalg.eigvals(H)[0])\n",
    "            print(\"Epoch {}, accuracy {:.2f}%, loss {:.6f}, nng {:.4g}, nnw {:.4g}, high_eig {:.4g}, low_eig {:.4g}.\"\\\n",
    "                    .format(i+1, get_accuracy()*100, v, nng, np.linalg.norm(w[:n_hidden]), max(eigs), min(eigs) ))\n",
    "#             display(w)\n",
    "            if nng < 1e-8:\n",
    "                flag = 1\n",
    "                break\n",
    "\n",
    "    if flag == 1:\n",
    "        v, H, w = sess.run([loss, hess, parameters], feed_dict={x: data, y_: label})    \n",
    "        eigs = sorted(np.linalg.eigvals(H)[0])\n",
    "        print(\"Epoch {}, accuracy {:.2f}%, loss {:.6f}, nng {:.4g}, nnw {:.4g}, high_eig {:.4g}, low_eig {:.4g}.\"\\\n",
    "                    .format(i+1, get_accuracy()*100, v, nng, np.linalg.norm(w[:n_hidden]), max(eigs), min(eigs) ))\n",
    "        display(w)\n",
    "#         displayH(H)\n",
    "#         dic[int(v * 1e5)] = dic.get(int(v * 1e5), []) + [(min(eigs), w)]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
