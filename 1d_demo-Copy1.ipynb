{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='2'\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1. ]\n",
      " [ 1. ]\n",
      " [ 0.1]\n",
      " [-0.1]] [[1]\n",
      " [1]\n",
      " [0]\n",
      " [0]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAD8CAYAAABkbJM/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSVITA0OS1MTAkCQ1MTAkSU3+P7VUDC73mAluAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x126a61780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "random.seed(3)\n",
    "\n",
    "def rand_cluster(n,c,r):\n",
    "    \"\"\"returns n random points in disk of radius r centered at c\"\"\"\n",
    "    x = c\n",
    "    points = []\n",
    "    for i in range(n):\n",
    "        theta = 2*math.pi*random.random()\n",
    "        s = r*random.random()\n",
    "        points.append([x+s*math.cos(theta)])\n",
    "    return points\n",
    "\n",
    "def rand_clusters(k,n,r, a,b,c,d):\n",
    "    \"\"\"return k clusters of n points each in random disks of radius r\n",
    "    where the centers of the disk are chosen randomly in [a,b]x[c,d]\"\"\"\n",
    "    clusters = []\n",
    "    for _ in range(k):\n",
    "        x = a + (b-a)*random.random()\n",
    "        y = c + (d-c)*random.random()\n",
    "        clusters.extend(rand_cluster(n,x,r))\n",
    "    return clusters\n",
    "\n",
    "n = 2\n",
    "X = rand_clusters(2,n,0.8,-1,1,-1,1)\n",
    "data = np.array(X)\n",
    "label = np.transpose(np.array([[1]*n + [0]*n]))\n",
    "\n",
    "# label = np.array([1]*n + [0]*n)\n",
    "data = []\n",
    "label = []\n",
    "data.append([-1])\n",
    "data.append([1])\n",
    "data.append([0.1])\n",
    "data.append([-0.1])\n",
    "label.append([1])\n",
    "label.append([1])\n",
    "label.append([0])\n",
    "label.append([0])\n",
    "data = np.array(data)\n",
    "label = np.array(label)\n",
    "print (data, label)\n",
    "\n",
    "plt.scatter(data[:n], [0]*n, color=['red'])\n",
    "plt.scatter(data[n:], [0]*n, color=['green'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tf.reset_default_graph()\n",
    "\n",
    "# def weight_variable(shape, name):\n",
    "#     initial = tf.truncated_normal(shape=shape, stddev=0.1)\n",
    "#     return tf.get_variable(name=name, initializer=initial)\n",
    "\n",
    "# def bias_variable(shape, name):\n",
    "#     initial = tf.constant(0.1, shape=shape)\n",
    "#     return tf.get_variable(name=name, initializer=initial)\n",
    "\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, 1])\n",
    "y_ = tf.placeholder(tf.float32, [None, 1])\n",
    "\n",
    "\n",
    "n_input = 1\n",
    "n_hidden = 2\n",
    "n_output = 1\n",
    "lmd = 0\n",
    "\n",
    "parameters = tf.Variable(tf.concat([tf.truncated_normal([n_input * n_hidden]), tf.zeros([n_hidden]),\\\n",
    "                                    tf.truncated_normal([n_hidden * n_output]), tf.zeros([n_output]),\\\n",
    "                                   ], 0))\n",
    "\n",
    "idx_from = 0 \n",
    "weights1 = tf.reshape(tf.slice(parameters, begin=[idx_from], size=[n_input*n_hidden]), [n_input, n_hidden])\n",
    "idx_from = idx_from + n_input*n_hidden\n",
    "biases1 = tf.reshape(tf.slice(parameters, begin=[idx_from], size=[n_hidden]), [n_hidden])\n",
    "hidden = tf.nn.relu(tf.matmul(x, weights1) + biases1)\n",
    "\n",
    "idx_from = idx_from + n_hidden\n",
    "weights2 = tf.reshape(tf.slice(parameters, begin=[idx_from], size=[n_hidden*n_output]), [n_hidden, n_output])\n",
    "idx_from = idx_from + n_hidden*n_output\n",
    "biases2 = tf.reshape(tf.slice(parameters, begin=[idx_from], size=[n_output]), [n_output])\n",
    "y = tf.nn.relu(tf.matmul(hidden, weights2) + biases2)\n",
    "\n",
    "loss = tf.reduce_mean(tf.reduce_sum(tf.pow(y_ - y, 2), reduction_indices=[1])) #I also tried simply tf.nn.l2_loss(y_ - y)\n",
    "\n",
    "lr = tf.placeholder(tf.float32, shape=[])\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=lr)\n",
    "grads_and_vars = optimizer.compute_gradients(loss)\n",
    "grad = tf.gradients(loss, parameters)\n",
    "hess = tf.hessians(loss, parameters)\n",
    "train_step = optimizer.apply_gradients(grads_and_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_accuracy():\n",
    "    pred = sess.run(y, feed_dict={x: data, y_: label})    \n",
    "    match = [(pred[i] - 0.5) * (label[i] - 0.5) > 0  for i in range(n*2)]\n",
    "    acc = sum(match)*1./2/n\n",
    "    return acc[0]\n",
    "\n",
    "def get_norm_grad():\n",
    "    nng = 0.\n",
    "    for gv in grad:\n",
    "#         print(str(sess.run(gv[0], feed_dict={x: data, y_: label})) + \" - \" + gv[1].name)\n",
    "        g = sess.run(gv, feed_dict={x: data, y_: label})\n",
    "#         print (g)\n",
    "        nng += np.linalg.norm(g) ** 2\n",
    "    return np.sqrt(nng)\n",
    "    \n",
    "     \n",
    "def displayH(a):\n",
    "    a = np.array(a[0])\n",
    "#     print (\"Matrix[\"+(\"%d\" %a.shape[0])+\"][\"+(\"%d\" %a.shape[1])+\"]\")\n",
    "    rows = a.shape[0]\n",
    "    cols = a.shape[1]\n",
    "    for i in range(0, rows):\n",
    "        for j in range(0, cols):\n",
    "            print(\"%0.2g \" %a[i,j], end=\"\")\n",
    "        print ()\n",
    "    print ()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Epoch 1, accuracy 50.00%, loss 0.428271, nng 0.7996, nnw 1.341, high_eig 2.294, low_eig -0.5772.\n",
      "1\n",
      "Epoch 1, accuracy 75.00%, loss 0.253181, nng 0.04245, nnw 2.095, high_eig 2.608, low_eig -0.002376.\n",
      "2\n",
      "Epoch 1, accuracy 50.00%, loss 0.452101, nng 0.5328, nnw 1.738, high_eig 1.124, low_eig -0.5337.\n",
      "3\n",
      "Epoch 1, accuracy 50.00%, loss 0.500000, nng 0, nnw 1.837, high_eig 0, low_eig 0.\n",
      "4\n",
      "Epoch 1, accuracy 50.00%, loss 0.500000, nng 0, nnw 0.8403, high_eig 0, low_eig 0.\n",
      "5\n",
      "Epoch 1, accuracy 75.00%, loss 0.144348, nng 0.4904, nnw 1.169, high_eig 4.071, low_eig -0.3143.\n",
      "6\n",
      "Epoch 1, accuracy 50.00%, loss 0.410626, nng 1.101, nnw 1.622, high_eig 4.826, low_eig -0.5285.\n",
      "7\n",
      "Epoch 1, accuracy 100.00%, loss 0.021371, nng 0.2448, nnw 1.243, high_eig 4.195, low_eig -0.09517.\n",
      "8\n",
      "Epoch 1, accuracy 50.00%, loss 0.500000, nng 0, nnw 0.7539, high_eig 0, low_eig 0.\n",
      "9\n",
      "Epoch 1, accuracy 75.00%, loss 0.297421, nng 0.4815, nnw 0.4102, high_eig 4.173, low_eig -0.2835.\n",
      "10\n",
      "Epoch 1, accuracy 50.00%, loss 0.500000, nng 0, nnw 1.204, high_eig 0, low_eig 0.\n",
      "11\n",
      "Epoch 1, accuracy 50.00%, loss 0.500000, nng 0, nnw 1.584, high_eig 0, low_eig 0.\n",
      "12\n",
      "Epoch 1, accuracy 50.00%, loss 0.334220, nng 0.7193, nnw 1.205, high_eig 4.365, low_eig -0.3793.\n",
      "13\n",
      "Epoch 1, accuracy 75.00%, loss 0.304613, nng 0.5565, nnw 0.9646, high_eig 4.718, low_eig -0.08646.\n",
      "14\n",
      "Epoch 1, accuracy 75.00%, loss 0.200084, nng 0.5946, nnw 0.6949, high_eig 6.139, low_eig -0.457.\n",
      "15\n",
      "Epoch 1, accuracy 50.00%, loss 0.500000, nng 0, nnw 1.207, high_eig 0, low_eig 0.\n",
      "16\n",
      "Epoch 1, accuracy 50.00%, loss 0.500000, nng 0, nnw 1.257, high_eig 0, low_eig 0.\n",
      "17\n",
      "Epoch 1, accuracy 75.00%, loss 1.761711, nng 5.007, nnw 1.426, high_eig 10.8, low_eig -1.859.\n",
      "18\n",
      "Epoch 1, accuracy 75.00%, loss 0.253290, nng 0.1428, nnw 1.15, high_eig 4.316, low_eig -0.0703.\n",
      "19\n",
      "Epoch 1, accuracy 50.00%, loss 0.500000, nng 0, nnw 1.111, high_eig 0, low_eig 0.\n"
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "l = 1e-1\n",
    "dic = {}\n",
    "\n",
    "for r in range(20):\n",
    "    \n",
    "    flag = 1\n",
    "    tf.global_variables_initializer().run()\n",
    "    w = sess.run([parameters], feed_dict={x: data, y_: label, lr: l})\n",
    "    dic[r] = w\n",
    " \n",
    "    for i in range(0):\n",
    "        sess.run(train_step, feed_dict={x: data, y_: label, lr: l})\n",
    "        nng = get_norm_grad()\n",
    "        if nng < 1e-4:\n",
    "            flag = 1\n",
    "            break\n",
    "\n",
    "    if flag == 1:\n",
    "        v, H, w = sess.run([loss, hess, parameters], feed_dict={x: data, y_: label, lr: l})    \n",
    "        nng = get_norm_grad()\n",
    "        eigs = sorted(np.linalg.eigvals(H)[0])\n",
    "        print (r)\n",
    "        print(\"Epoch {}, accuracy {:.2f}%, loss {:.6f}, nng {:.4g}, nnw {:.4g}, high_eig {:.4g}, low_eig {:.4g}.\"\\\n",
    "                .format(i+1, get_accuracy()*100, v, nng, np.linalg.norm(w[:n_hidden]), max(eigs), min(eigs) ))\n",
    "        \n",
    "#         print (w)\n",
    "#             h = sess.run([y], feed_dict={x: data, y_: label})    \n",
    "#         print (h)\n",
    "sess.close() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "3.19:\n",
    "\n",
    "Relu is helpful to obtain flat region. For example, zero is not a first order stationary point while using sigmoid, but indeed is while using relu.\n",
    "    \n",
    "For sigmoid, point far away from 0 tends to have tiny gradient.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sol = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.54967874  0.46465215  0.          0.          0.85924828  1.13367045\n",
      "  0.        ]\n"
     ]
    }
   ],
   "source": [
    "idx = 45\n",
    "print (dic[idx][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100, accuracy 100.00%, loss 0.000000, nng 8.756e-08, nnw 1.312, high_eig 3.455, low_eig -3.519e-08.\n",
      "[-0.9774105   0.87449503 -0.09644938 -0.08832376  1.13679051  1.27385521\n",
      " -0.00146833]\n"
     ]
    }
   ],
   "source": [
    "private_init = parameters.assign(dic[idx][0])\n",
    "sess = tf.InteractiveSession()\n",
    "l = 5e-1\n",
    "\n",
    "tf.global_variables_initializer().run()\n",
    "sess.run(private_init)    \n",
    "v, H, w = sess.run([loss, hess, parameters], feed_dict={x: data, y_: label, lr: l})    \n",
    "nng = get_norm_grad()\n",
    "# print (sess.run(grad[0], feed_dict={x: data, y_: label}))\n",
    "\n",
    "for i in range(100):\n",
    "    sess.run(train_step, feed_dict={x: data, y_: label, lr: l})\n",
    "    v, H, w = sess.run([loss, hess, parameters], feed_dict={x: data, y_: label, lr: l})    \n",
    "    nng = get_norm_grad()\n",
    "    eigs = sorted(np.linalg.eigvals(H)[0])\n",
    "print(\"Epoch {}, accuracy {:.2f}%, loss {:.6f}, nng {:.4g}, nnw {:.4g}, high_eig {:.4g}, low_eig {:.4g}.\"\\\n",
    "            .format(i+1, get_accuracy()*100, v, nng, np.linalg.norm(w[:n_hidden]), max(eigs), min(eigs) ))\n",
    "#     print (sess.run(grad[0], feed_dict={x: data, y_: label}))\n",
    "#     print (w)\n",
    "sol[idx] = w\n",
    "print (sol[idx])\n",
    "sess.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{15: array([ 1.75133431, -1.00075877, -0.07483343, -0.01163835,  0.65504843,\n",
       "         1.11026835, -0.09818926], dtype=float32),\n",
       " 45: array([-0.9774105 ,  0.87449503, -0.09644938, -0.08832376,  1.13679051,\n",
       "         1.27385521, -0.00146833], dtype=float32)}"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.79397285 -0.81013817  0.          0.          0.74770951  0.9456349   0.        ]\n",
      "Epoch 100, accuracy 100.00%, loss 7.56339e-15, nng 7.985e-08, nnw 2.017, high_eig 3.446, low_eig -9.984e-09.\n",
      "[ 1.75133431 -1.00075877 -0.07483343 -0.01163835  0.65504843  1.11026835\n",
      " -0.09818926]\n",
      "Epoch 100, accuracy 100.00%, loss 7.56339e-15, nng 0.9949, nnw 2.928, high_eig 3.446, low_eig -9.984e-09.\n"
     ]
    }
   ],
   "source": [
    "w0 = dic[15][0]\n",
    "print (w0)\n",
    "private_init = parameters.assign(w0)\n",
    "sess = tf.InteractiveSession()\n",
    "l = 5e-1\n",
    "\n",
    "tf.global_variables_initializer().run()\n",
    "sess.run(private_init)    \n",
    "v, H, w = sess.run([loss, hess, parameters], feed_dict={x: data, y_: label, lr: l})    \n",
    "nng = get_norm_grad()\n",
    "# print (sess.run(grad[0], feed_dict={x: data, y_: label}))\n",
    "\n",
    "for i in range(100):\n",
    "    sess.run(train_step, feed_dict={x: data, y_: label, lr: l})\n",
    "    v, H, w = sess.run([loss, hess, parameters], feed_dict={x: data, y_: label, lr: l})    \n",
    "    nng = get_norm_grad()\n",
    "    eigs = sorted(np.linalg.eigvals(H)[0])\n",
    "print(\"Epoch {}, accuracy {:.2f}%, loss {:.6g}, nng {:.4g}, nnw {:.4g}, high_eig {:.4g}, low_eig {:.4g}.\"\\\n",
    "            .format(i+1, get_accuracy()*100, v, nng, np.linalg.norm(w[:n_hidden]), max(eigs), min(eigs) ))\n",
    "print (w)\n",
    "w[0] += 1e-0\n",
    "private_init = parameters.assign(w)\n",
    "sess.run(private_init)    \n",
    "nng = get_norm_grad()\n",
    "print(\"Epoch {}, accuracy {:.2f}%, loss {:.6g}, nng {:.4g}, nnw {:.4g}, high_eig {:.4g}, low_eig {:.4g}.\"\\\n",
    "            .format(i+1, get_accuracy()*100, v, nng, np.linalg.norm(w[:n_hidden]), max(eigs), min(eigs) ))\n",
    "\n",
    "sess.close() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.20:\n",
    "    This example shows, initialization is more important than optimization, to reach 100% training accuracy. \n",
    "    \n",
    "    Also, for 1d data, weights are not important. It is bias that works. It may be possible to visualize the landscape since there are only 3 bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
