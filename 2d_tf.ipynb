{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='2'\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\npgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x122133da0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "random.seed(3)\n",
    "\n",
    "def rand_cluster(n,c,r):\n",
    "    \"\"\"returns n random points in disk of radius r centered at c\"\"\"\n",
    "    x,y = c\n",
    "    points = []\n",
    "    for i in range(n):\n",
    "        theta = 2*math.pi*random.random()\n",
    "        s = r*random.random()\n",
    "        points.append((x+s*math.cos(theta), y+s*math.sin(theta)))\n",
    "    return points\n",
    "\n",
    "def rand_clusters(k,n,r, a,b,c,d):\n",
    "    \"\"\"return k clusters of n points each in random disks of radius r\n",
    "    where the centers of the disk are chosen randomly in [a,b]x[c,d]\"\"\"\n",
    "    clusters = []\n",
    "    for _ in range(k):\n",
    "        x = a + (b-a)*random.random()\n",
    "        y = c + (d-c)*random.random()\n",
    "        clusters.extend(rand_cluster(n,(x,y),r))\n",
    "    return clusters\n",
    "\n",
    "n = 50\n",
    "X = rand_clusters(2,50,1.8,-1,1,-1,1)\n",
    "data = np.array(X)\n",
    "label = np.transpose(np.array([[1]*n + [0]*n, [0]*n + [1]*n]))\n",
    "# label = np.array([1]*n + [0]*n)\n",
    "# print (data, label)\n",
    "\n",
    "plt.scatter(data[:n,0], data[:n,1], color=['red'])\n",
    "plt.scatter(data[n:,0], data[n:,1], color=['green'])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "def weight_variable(shape, name):\n",
    "    initial = tf.truncated_normal(shape=shape, stddev=0.1)\n",
    "    return tf.get_variable(name=name, initializer=initial)\n",
    "\n",
    "def bias_variable(shape, name):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.get_variable(name=name, initializer=initial)\n",
    "\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, 2])\n",
    "y_ = tf.placeholder(tf.float32, [None, 2])\n",
    "\n",
    "#hidden layer\n",
    "# W_fc1 = weight_variable([2, 4], 'W1')\n",
    "# b_fc1 = bias_variable([4], 'b1')\n",
    "# h_fc1 = tf.sigmoid(tf.matmul(x, W_fc1) + b_fc1)\n",
    "# #output layer\n",
    "# W_fc2 = weight_variable([4, 2], 'W2')\n",
    "# b_fc2 = bias_variable([2], 'b2')\n",
    "# y = tf.sigmoid(tf.matmul(h_fc1, W_fc2) + b_fc2)\n",
    "\n",
    "n_input = 2\n",
    "n_hidden = 4\n",
    "n_hidden2 = 5\n",
    "n_output = 2\n",
    "lmd = 1e-4\n",
    "# parameters = tf.Variable(tf.concat([tf.truncated_normal([n_input * n_hidden]), tf.zeros([n_hidden]),\\\n",
    "                            # tf.truncated_normal([n_hidden * n_output]), tf.zeros([n_output])],0))\n",
    "parameters = tf.Variable(tf.concat([tf.truncated_normal([n_input * n_hidden]), tf.zeros([n_hidden]),\\\n",
    "#                                     tf.truncated_normal([n_hidden * n_hidden2]), tf.zeros([n_hidden2]),\\\n",
    "                                    tf.truncated_normal([n_hidden * n_output]), tf.zeros([n_output]),\\\n",
    "                                   ], 0))\n",
    "\n",
    "idx_from = 0 \n",
    "weights1 = tf.reshape(tf.slice(parameters, begin=[idx_from], size=[n_input*n_hidden]), [n_input, n_hidden])\n",
    "idx_from = idx_from + n_input*n_hidden\n",
    "biases1 = tf.reshape(tf.slice(parameters, begin=[idx_from], size=[n_hidden]), [n_hidden])\n",
    "hidden = tf.sigmoid(tf.matmul(x, weights1) + biases1)\n",
    "\n",
    "idx_from = idx_from + n_hidden\n",
    "weights2 = tf.reshape(tf.slice(parameters, begin=[idx_from], size=[n_hidden*n_output]), [n_hidden, n_output])\n",
    "idx_from = idx_from + n_hidden*n_output\n",
    "biases2 = tf.reshape(tf.slice(parameters, begin=[idx_from], size=[n_output]), [n_output])\n",
    "y = tf.nn.sigmoid(tf.matmul(hidden, weights2) + biases2)\n",
    "\n",
    "# idx_from = idx_from + n_hidden\n",
    "# weights2 = tf.reshape(tf.slice(parameters, begin=[idx_from], size=[n_hidden*n_hidden2]), [n_hidden, n_hidden2])\n",
    "# idx_from = idx_from + n_hidden*n_hidden2\n",
    "# biases2 = tf.reshape(tf.slice(parameters, begin=[idx_from], size=[n_hidden2]), [n_hidden2])\n",
    "# hidden2 = tf.sigmoid(tf.matmul(hidden, weights2) + biases2)\n",
    "\n",
    "# idx_from = idx_from + n_hidden2\n",
    "# weights3 = tf.reshape(tf.slice(parameters, begin=[idx_from], size=[n_hidden2*n_output]), [n_hidden2, n_output])\n",
    "# idx_from = idx_from + n_hidden2*n_output\n",
    "# biases3 = tf.reshape(tf.slice(parameters, begin=[idx_from], size=[n_output]), [n_output])\n",
    "# y = tf.nn.sigmoid(tf.matmul(hidden2, weights3) + biases3)\n",
    "\n",
    "weights = tf.concat([tf.reshape(weights1, [-1]), tf.reshape(weights2, [-1])], 0)\n",
    "regularizer = tf.nn.l2_loss(weights)\n",
    "\n",
    "los = tf.reduce_mean(tf.reduce_sum(tf.pow(y_ - y, 2), reduction_indices=[1])) #I also tried simply tf.nn.l2_loss(y_ - y)\n",
    "loss = los + lmd * regularizer\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(1e-0)\n",
    "grads_and_vars = optimizer.compute_gradients(loss)\n",
    "hess = tf.hessians(loss, parameters)\n",
    "train_step = optimizer.apply_gradients(grads_and_vars)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_accuracy():\n",
    "    correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    return sess.run(accuracy, feed_dict={x: data, y_: label})\n",
    "\n",
    "def get_norm_grad():\n",
    "    nng = 0.\n",
    "    for gv in grads_and_vars:\n",
    "        # print(str(sess.run(gv[0], feed_dict={x: data, y_: label})) + \" - \" + gv[1].name)\n",
    "        grad = sess.run(gv[0], feed_dict={x: data, y_: label})\n",
    "        nng += np.linalg.norm(grad[0]) ** 2\n",
    "    return np.sqrt(nng)\n",
    "\n",
    "def display(w):\n",
    "\n",
    "    idx_from = 0 \n",
    "    weights1 = np.reshape(w[idx_from: n_input*n_hidden], [n_input, n_hidden])\n",
    "    idx_from = idx_from + n_input*n_hidden\n",
    "    biases1 = np.reshape(w[idx_from: idx_from+n_hidden], [n_hidden])\n",
    "    idx_from = idx_from + n_hidden\n",
    "    weights2 = np.reshape(w[idx_from: idx_from+n_hidden*n_output], [n_hidden, n_output])\n",
    "    idx_from = idx_from + n_hidden*n_output\n",
    "    biases2 = np.reshape(w[idx_from: idx_from+n_output], [n_output])\n",
    "    print (weights1)\n",
    "    print (biases1)\n",
    "    print (weights2)\n",
    "    print (biases2)\n",
    "    \n",
    "     \n",
    "def displayH(a):\n",
    "    a = np.array(a[0])\n",
    "#     print (\"Matrix[\"+(\"%d\" %a.shape[0])+\"][\"+(\"%d\" %a.shape[1])+\"]\")\n",
    "    rows = a.shape[0]\n",
    "    cols = a.shape[1]\n",
    "    for i in range(0, rows):\n",
    "        for j in range(0, cols):\n",
    "            print(\"%0.2g \" %a[i,j], end=\"\")\n",
    "        print ()\n",
    "    print ()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 239, accuracy 76.00%, loss 0.320315, nng 9.604e-09, nnw 14.59, high_eig 0.1045, low_eig 7.254e-14.\n",
      "Epoch 169, accuracy 76.00%, loss 0.351368, nng 8.277e-09, nnw 8.203, high_eig 0.09372, low_eig -9.204e-13.\n",
      "Epoch 190, accuracy 76.00%, loss 0.342640, nng 3.776e-09, nnw 7.778, high_eig 0.156, low_eig 3.987e-12.\n",
      "Epoch 207, accuracy 77.00%, loss 0.320345, nng 7.135e-09, nnw 14.63, high_eig 0.1054, low_eig -4.172e-09.\n",
      "Epoch 192, accuracy 75.00%, loss 0.346984, nng 4.143e-09, nnw 8.537, high_eig 0.08386, low_eig -4.931e-12.\n",
      "Epoch 168, accuracy 78.00%, loss 0.336357, nng 6.228e-09, nnw 7.768, high_eig 0.08369, low_eig -1.204e-08.\n",
      "Epoch 213, accuracy 78.00%, loss 0.340902, nng 9.313e-10, nnw 5.781, high_eig 0.08985, low_eig -3.004e-10.\n",
      "Epoch 155, accuracy 75.00%, loss 0.330497, nng 5.466e-09, nnw 12.43, high_eig 0.09789, low_eig -1.428e-06.\n",
      "Epoch 265, accuracy 78.00%, loss 0.340901, nng 3.9e-09, nnw 5.781, high_eig 0.08985, low_eig -6.05e-15.\n",
      "Epoch 202, accuracy 76.00%, loss 0.351373, nng 4.366e-09, nnw 8.202, high_eig 0.0937, low_eig -5.146e-09.\n"
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "\n",
    "dic = {}\n",
    "for _ in range(100):\n",
    "\n",
    "    tf.global_variables_initializer().run()\n",
    "    flag = 0\n",
    "    for i in range(1000):\n",
    "        sess.run(train_step, feed_dict={x: data, y_: label})\n",
    "        nng = get_norm_grad()\n",
    "        if nng < 1e-8:\n",
    "            flag = 1\n",
    "            break\n",
    "\n",
    "    if flag == 1:\n",
    "        v, H, w = sess.run([loss, hess, parameters], feed_dict={x: data, y_: label})    \n",
    "        eigs = sorted(np.linalg.eigvals(H)[0])\n",
    "        print(\"Epoch {}, accuracy {:.2f}%, loss {:.6f}, nng {:.4g}, nnw {:.4g}, high_eig {:.4g}, low_eig {:.4g}.\"\\\n",
    "                    .format(i+1, get_accuracy()*100, v, nng, np.linalg.norm(w[:n_hidden]), max(eigs), min(eigs) ))\n",
    "#         display(w)\n",
    "#         displayH(H)\n",
    "        dic[int(v * 1e5)] = dic.get(int(v * 1e5), []) + [(min(eigs), w)]\n",
    "sess.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33025:\n",
      "-1.29028e-09\n",
      "[[  2.00981041e-04  -1.16835375e+01  -1.98152359e-03  -4.53153992e+00]\n",
      " [ -4.73890221e-03   3.50707793e+00   2.83185486e-03  -6.81287527e+00]]\n",
      "[-10.46237755  -5.12524939  -7.76072836  -0.88010037]\n",
      "[[  1.34084508e-01  -2.05596127e-02]\n",
      " [  2.15846109e+00  -2.15289426e+00]\n",
      " [ -1.13073774e-01  -4.63075907e-04]\n",
      " [  2.51508069e+00  -2.50468469e+00]]\n",
      "[-2.17556763  2.16860509]\n",
      "33026:\n",
      "-1.55254e-09\n",
      "[[ -2.80412380e-03  -1.16904478e+01   4.51984310e+00  -3.05295951e-04]\n",
      " [ -8.28090357e-04   3.50562286e+00   6.80034399e+00  -8.80599953e-04]]\n",
      "[ -9.25848389  -5.12742472   0.87862444 -11.90273952]\n",
      "[[-0.31488526  0.27877745]\n",
      " [ 2.15394998 -2.15380001]\n",
      " [-2.50726295  2.50705814]\n",
      " [-0.20662026  0.06780826]]\n",
      "[ 0.33813208 -0.33804536]\n",
      "33633:\n",
      "-7.01337e-12\n",
      "[[  6.16855049e+00  -1.23263846e-04  -4.37604284e+00  -1.78496468e+00]\n",
      " [  5.55536222e+00   2.20564441e-04  -1.69206452e+00   7.79499197e+00]]\n",
      "[  0.48234153  -9.76311588  -7.37112999 -12.24971104]\n",
      "[[-2.79343224  2.7932663 ]\n",
      " [ 0.03968063 -0.01291695]\n",
      " [ 2.41916394 -2.41959763]\n",
      " [ 4.33962297 -4.33938122]]\n",
      "[ 1.01446021 -1.01440656]\n",
      "34090:\n",
      "-1.03274e-09\n",
      "[[  5.46798576e-04  -2.11981702e+00   5.36526871e+00   1.25984503e-02]\n",
      " [ -9.59660392e-04   7.45365858e+00   4.79435873e+00  -7.51669693e-04]]\n",
      "[-10.89457417 -12.07284737   0.71664113  -8.65525913]\n",
      "[[-0.31993026  0.21568955]\n",
      " [ 4.31056118 -4.31975555]\n",
      " [-3.16274166  3.162709  ]\n",
      " [-0.05336861  0.04315174]]\n",
      "[ 1.37707722 -1.37700808]\n",
      "34242:\n",
      "-7.71845e-12\n",
      "[[  5.39067783e-04   1.63752527e-03   5.97727394e+00  -5.10521507e+00]\n",
      " [ -1.50970696e-03   3.06297239e-04   6.00231826e-01  -2.62632227e+00]]\n",
      "[ -7.94655752 -10.00823689  -2.76189017   0.22726521]\n",
      "[[-0.02372993 -0.00823718]\n",
      " [ 0.01509513  0.01495692]\n",
      " [ 2.82331276 -2.82175326]\n",
      " [ 4.84926653 -4.8479557 ]]\n",
      "[-3.55478311  3.55343413]\n",
      "34690:\n",
      "-5.27629e-10\n",
      "[[ -3.95772910e+00  -1.91370373e-06   2.86744162e-03   4.01692569e-01]\n",
      " [ -6.03244066e+00  -6.41144015e-06  -3.88595770e-04  -6.99501419e+00]]\n",
      "[ -0.68523216 -10.77275658  -7.74034071   0.2304142 ]\n",
      "[[  4.90870953e+00  -4.90862322e+00]\n",
      " [  3.20907457e-05   3.23919994e-05]\n",
      " [ -3.01832594e-02   4.28738492e-03]\n",
      " [ -3.01530147e+00   3.01511979e+00]]\n",
      "[-1.026016   1.0261023]\n",
      "35141:\n",
      "-6.26514e-08\n",
      "[[ -4.33276606e+00   1.94500593e-04   6.96425819e+00  -1.09597901e-02]\n",
      " [ -5.74963808e+00  -3.63342115e-04   3.71346855e+00   1.57939121e-02]]\n",
      "[-1.24889565 -8.68399525 -0.04064481 -8.6753931 ]\n",
      "[[ 1.2110517  -1.21076   ]\n",
      " [ 0.0030226   0.02593139]\n",
      " [-2.18715715  2.18718457]\n",
      " [ 0.092911   -1.01268792]]\n",
      "[ 0.31040528 -0.31045529]\n",
      "35369:\n",
      "9.19441e-12\n",
      "[[ -2.45766336e-04  -6.13942146e+00   1.82290026e-03  -4.55972593e-04]\n",
      " [  4.46218706e-04  -3.85668015e+00  -1.78032133e-04  -5.25873853e-04]]\n",
      "[ -8.45194912  -0.03266767  -9.85370731 -10.66936588]\n",
      "[[  2.88478788e-02   1.24413357e-03]\n",
      " [  3.14767218e+00  -3.14776397e+00]\n",
      " [ -1.38459662e-02  -3.13856006e-02]\n",
      " [  1.95883349e-01  -1.12080038e-01]]\n",
      "[-1.88943553  1.88946104]\n"
     ]
    }
   ],
   "source": [
    "for key in sorted(dic):\n",
    "    print (\"%s:\" % (key))\n",
    "    for e, v in dic[key]:\n",
    "        print (e)\n",
    "        display(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w0 = np.array([10,0,0,0,1,0,0,0, \n",
    "              0,0,0,0,\n",
    "              0,0,0,0,0,0,0,0, \n",
    "              0,0])\n",
    "private_init = parameters.assign(w0)\n",
    "\n",
    "idx = [1,2,3,5,6,7,\n",
    "            9,10,11] + \\\n",
    "            list(range(14,20))\n",
    "fix_coordinate = []\n",
    "for i in idx:\n",
    "    fix_coordinate.append(parameters[i].assign(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 204, accuracy 75.00%, loss 0.353688, nng 6.461e-09, nnw 6.138, high_eig 0.1378, low_eig -0.001555.\n",
      "[[ 6.1384387   0.          0.          0.        ]\n",
      " [ 3.85529733  0.          0.          0.        ]]\n",
      "[ 0.0328644  0.         0.         0.       ]\n",
      "[[-3.14847136  3.14847159]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]]\n",
      "[ 1.25850093 -1.25850058]\n",
      "Epoch 256, accuracy 75.00%, loss 0.330258, nng 2.619e-10, nnw 12.53, high_eig 0.1263+0j, low_eig -0.001666+0j.\n",
      "[[  4.52024651 -11.69125748   0.           0.        ]\n",
      " [  6.80131388   3.50514174   0.           0.        ]]\n",
      "[ 0.87811577 -5.12807369  0.          0.        ]\n",
      "[[-2.50723052  2.50723052]\n",
      " [ 2.15404177 -2.15404272]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]]\n",
      "[ 0.3379378  -0.33793768]\n",
      "Epoch 171, accuracy 75.00%, loss 0.330258, nng 5.093e-09, nnw 12.53, high_eig 0.1119, low_eig -0.001501.\n",
      "[[  4.52028894e+00  -1.16912632e+01   2.49887467e-04   0.00000000e+00]\n",
      " [  6.80136728e+00   3.50522685e+00  -8.83873668e-04   0.00000000e+00]]\n",
      "[  0.87811351  -5.128088   -15.73108006   0.        ]\n",
      "[[ -2.50726461e+00   2.50718856e+00]\n",
      " [  2.15400386e+00  -2.15406132e+00]\n",
      " [ -1.24359518e-04   4.06605104e-04]\n",
      " [  0.00000000e+00   0.00000000e+00]]\n",
      "[ 0.33794069 -0.33793011]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "dic = {}\n",
    "for _ in range(1):\n",
    "\n",
    "    tf.global_variables_initializer().run()\n",
    "    sess.run(private_init)    \n",
    "    flag = 0\n",
    "    for i in range(1000):\n",
    "        sess.run(train_step, feed_dict={x: data, y_: label})\n",
    "        for op in fix_coordinate:\n",
    "            sess.run(op)\n",
    "        nng = get_norm_grad()\n",
    "        if nng < 1e-8:\n",
    "            flag = 1\n",
    "            break\n",
    "\n",
    "    if flag == 1:\n",
    "        v, H, w = sess.run([loss, hess, parameters], feed_dict={x: data, y_: label})    \n",
    "        eigs = sorted(np.linalg.eigvals(H)[0])\n",
    "        print(\"Epoch {}, accuracy {:.2f}%, loss {:.6f}, nng {:.4g}, nnw {:.4g}, high_eig {:.4g}, low_eig {:.4g}.\"\\\n",
    "                    .format(i+1, get_accuracy()*100, v, nng, np.linalg.norm(w[:n_hidden]), max(eigs), min(eigs) ))\n",
    "        display(w)\n",
    "#         displayH(H)\n",
    "#         dic[int(v * 1e5)] = dic.get(int(v * 1e5), []) + [(min(eigs), w)]\n",
    "    \n",
    "    \n",
    "    idx = [2,3,6,7,\n",
    "            10,11] + \\\n",
    "            list(range(16,20))\n",
    "    fix_coordinate2 = []\n",
    "    for i in idx:\n",
    "        fix_coordinate2.append(parameters[i].assign(0))\n",
    "    flag = 0\n",
    "    sess.run(parameters[1].assign(1.))\n",
    "    for i in range(1000):\n",
    "        sess.run(train_step, feed_dict={x: data, y_: label})\n",
    "        for op in fix_coordinate2:\n",
    "            sess.run(op)\n",
    "        nng = get_norm_grad()\n",
    "        if nng < 1e-8:\n",
    "            flag = 1\n",
    "            break\n",
    "\n",
    "    if flag == 1:\n",
    "        v, H, w = sess.run([loss, hess, parameters], feed_dict={x: data, y_: label})    \n",
    "        eigs = sorted(np.linalg.eigvals(H)[0])\n",
    "        print(\"Epoch {}, accuracy {:.2f}%, loss {:.6f}, nng {:.4g}, nnw {:.4g}, high_eig {:.4g}, low_eig {:.4g}.\"\\\n",
    "                    .format(i+1, get_accuracy()*100, v, nng, np.linalg.norm(w[:n_hidden]), max(eigs), min(eigs) ))\n",
    "        display(w)\n",
    "        \n",
    "    idx = [3,7,\n",
    "            11] + \\\n",
    "            list(range(18,20))\n",
    "    fix_coordinate2 = []\n",
    "    for i in idx:\n",
    "        fix_coordinate2.append(parameters[i].assign(0))\n",
    "    flag = 1\n",
    "    sess.run(parameters[17].assign(.5))\n",
    "    for i in range(1000):\n",
    "        sess.run(train_step, feed_dict={x: data, y_: label})\n",
    "        for op in fix_coordinate2:\n",
    "            sess.run(op)\n",
    "        nng = get_norm_grad()\n",
    "        if nng < 1e-8:\n",
    "            flag = 1\n",
    "            break\n",
    "\n",
    "    if flag == 1:\n",
    "        v, H, w = sess.run([loss, hess, parameters], feed_dict={x: data, y_: label})    \n",
    "        eigs = sorted(np.linalg.eigvals(H)[0])\n",
    "        print(\"Epoch {}, accuracy {:.2f}%, loss {:.6f}, nng {:.4g}, nnw {:.4g}, high_eig {:.4g}, low_eig {:.4g}.\"\\\n",
    "                    .format(i+1, get_accuracy()*100, v, nng, np.linalg.norm(w[:n_hidden]), max(eigs), min(eigs) ))\n",
    "        display(w)\n",
    "         \n",
    "sess.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, accuracy 50.00%, loss 0.500010, nng 0.0002347, nnw 0, high_eig 0.2519+0j, low_eig -0.03067+0j.\n",
      "Epoch 21, accuracy 76.00%, loss 0.411710, nng 0.003837, nnw 7.449, high_eig 0.07424+0j, low_eig -0.008044+0j.\n",
      "Epoch 41, accuracy 74.00%, loss 0.385667, nng 0.002368, nnw 6.098, high_eig 0.09105+0j, low_eig -0.002281+0j.\n",
      "Epoch 61, accuracy 76.00%, loss 0.358243, nng 0.002596, nnw 6.689, high_eig 0.08753+0j, low_eig 2.384e-06+0j.\n",
      "Epoch 81, accuracy 75.00%, loss 0.355528, nng 0.0002112, nnw 6.816, high_eig 0.112, low_eig 2.84e-07.\n",
      "Epoch 101, accuracy 75.00%, loss 0.354500, nng 0.0006012, nnw 6.072, high_eig 0.1066, low_eig -3.075e-07.\n",
      "Epoch 121, accuracy 75.00%, loss 0.354023, nng 8.551e-05, nnw 6.075, high_eig 0.1095, low_eig 2.073e-08.\n",
      "Epoch 141, accuracy 75.00%, loss 0.353827, nng 9.836e-05, nnw 6.169, high_eig 0.1093+0j, low_eig 2.355e-09+0j.\n",
      "Epoch 161, accuracy 75.00%, loss 0.353739, nng 2.179e-05, nnw 6.133, high_eig 0.1092+0j, low_eig 4.086e-10+0j.\n",
      "Epoch 181, accuracy 75.00%, loss 0.353705, nng 8.466e-06, nnw 6.139, high_eig 0.1091, low_eig -5.671e-10.\n",
      "Epoch 201, accuracy 75.00%, loss 0.353693, nng 4.038e-06, nnw 6.139, high_eig 0.1091+0j, low_eig -3.28e-10+0j.\n",
      "Epoch 221, accuracy 75.00%, loss 0.353689, nng 2.366e-07, nnw 6.138, high_eig 0.1091+0j, low_eig -1.109e-10+0j.\n",
      "Epoch 241, accuracy 75.00%, loss 0.353688, nng 5.922e-07, nnw 6.139, high_eig 0.1091+0j, low_eig -2.507e-11+0j.\n",
      "Epoch 261, accuracy 75.00%, loss 0.353688, nng 1.872e-07, nnw 6.139, high_eig 0.1091+0j, low_eig -4.502e-12+0j.\n",
      "Epoch 281, accuracy 75.00%, loss 0.353688, nng 4.796e-08, nnw 6.139, high_eig 0.1091, low_eig -9.982e-13.\n",
      "Epoch 301, accuracy 75.00%, loss 0.353688, nng 2.852e-09, nnw 6.139, high_eig 0.1091+0j, low_eig -1.588e-13+0j.\n",
      "Epoch 301, accuracy 75.00%, loss 0.353688, nng 2.852e-09, nnw 6.139, high_eig 0.1091+0j, low_eig -1.588e-13+0j.\n",
      "[[ -6.13854933e+00  -3.11641015e-05  -3.11641015e-05  -3.11641015e-05]\n",
      " [ -3.85536432e+00   9.52157370e-06   9.52157370e-06   9.52157370e-06]]\n",
      "[-0.0328153  -9.17983055 -9.17983055 -9.17983055]\n",
      "[[  3.14850545e+00  -3.14850569e+00]\n",
      " [  2.66322237e-03  -2.66322074e-03]\n",
      " [  2.66322237e-03  -2.66322074e-03]\n",
      " [  2.66322237e-03  -2.66322074e-03]]\n",
      "[-1.88999593  1.88999641]\n"
     ]
    }
   ],
   "source": [
    "w0 = np.array([0,0,0,0,0,0,0,0, \n",
    "              1e-4,0,0,0,\n",
    "              0,0,0,0,0,0,0,0, \n",
    "              0,0])\n",
    "# w0 = np.array([0.5]*22)\n",
    "private_init = parameters.assign(w0)\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "dic = {}\n",
    "for _ in range(1):\n",
    "\n",
    "    tf.global_variables_initializer().run()\n",
    "    sess.run(private_init)    \n",
    "    flag = 1\n",
    "    for i in range(1000):\n",
    "#         idx = random.randint(0, 9)\n",
    "#         sess.run(train_step, feed_dict={x: data[idx*10: (idx+1)*10], y_: label[idx*10: (idx+1)*10]})\n",
    "        sess.run(train_step, feed_dict={x: data, y_: label})\n",
    "        \n",
    "        if i % 20 == 0:\n",
    "            v, H, w = sess.run([loss, hess, parameters], feed_dict={x: data, y_: label})    \n",
    "            nng = get_norm_grad()\n",
    "            eigs = sorted(np.linalg.eigvals(H)[0])\n",
    "            print(\"Epoch {}, accuracy {:.2f}%, loss {:.6f}, nng {:.4g}, nnw {:.4g}, high_eig {:.4g}, low_eig {:.4g}.\"\\\n",
    "                    .format(i+1, get_accuracy()*100, v, nng, np.linalg.norm(w[:n_hidden]), max(eigs), min(eigs) ))\n",
    "#             display(w)\n",
    "            if nng < 1e-8:\n",
    "                flag = 1\n",
    "                break\n",
    "\n",
    "    if flag == 1:\n",
    "        v, H, w = sess.run([loss, hess, parameters], feed_dict={x: data, y_: label})    \n",
    "        eigs = sorted(np.linalg.eigvals(H)[0])\n",
    "        print(\"Epoch {}, accuracy {:.2f}%, loss {:.6f}, nng {:.4g}, nnw {:.4g}, high_eig {:.4g}, low_eig {:.4g}.\"\\\n",
    "                    .format(i+1, get_accuracy()*100, v, nng, np.linalg.norm(w[:n_hidden]), max(eigs), min(eigs) ))\n",
    "        display(w)\n",
    "#         displayH(H)\n",
    "#         dic[int(v * 1e5)] = dic.get(int(v * 1e5), []) + [(min(eigs), w)]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
