{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='2'\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\npgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd5a9308908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "random.seed(3)\n",
    "\n",
    "def rand_cluster(n,c,r):\n",
    "    \"\"\"returns n random points in disk of radius r centered at c\"\"\"\n",
    "    x,y = c\n",
    "    points = []\n",
    "    for i in range(n):\n",
    "        theta = 2*math.pi*random.random()\n",
    "        s = r*random.random()\n",
    "        points.append((x+s*math.cos(theta), y+s*math.sin(theta)))\n",
    "    return points\n",
    "\n",
    "def rand_clusters(k,n,r, a,b,c,d):\n",
    "    \"\"\"return k clusters of n points each in random disks of radius r\n",
    "    where the centers of the disk are chosen randomly in [a,b]x[c,d]\"\"\"\n",
    "    clusters = []\n",
    "    for _ in range(k):\n",
    "        x = a + (b-a)*random.random()\n",
    "        y = c + (d-c)*random.random()\n",
    "        clusters.extend(rand_cluster(n,(x,y),r))\n",
    "    return clusters\n",
    "\n",
    "n = 50\n",
    "X = rand_clusters(2,50,1.8,-1,1,-1,1)\n",
    "data = np.array(X)\n",
    "label = np.transpose(np.array([[1]*n + [0]*n, [0]*n + [1]*n]))\n",
    "# label = np.array([1]*n + [0]*n)\n",
    "# print (data, label)\n",
    "\n",
    "plt.scatter(data[:n,0], data[:n,1], color=['red'])\n",
    "plt.scatter(data[n:,0], data[n:,1], color=['green'])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "def weight_variable(shape, name):\n",
    "    initial = tf.truncated_normal(shape=shape, stddev=0.1)\n",
    "    return tf.get_variable(name=name, initializer=initial)\n",
    "\n",
    "def bias_variable(shape, name):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.get_variable(name=name, initializer=initial)\n",
    "\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, 2])\n",
    "y_ = tf.placeholder(tf.float32, [None, 2])\n",
    "\n",
    "#hidden layer\n",
    "# W_fc1 = weight_variable([2, 4], 'W1')\n",
    "# b_fc1 = bias_variable([4], 'b1')\n",
    "# h_fc1 = tf.sigmoid(tf.matmul(x, W_fc1) + b_fc1)\n",
    "# #output layer\n",
    "# W_fc2 = weight_variable([4, 2], 'W2')\n",
    "# b_fc2 = bias_variable([2], 'b2')\n",
    "# y = tf.sigmoid(tf.matmul(h_fc1, W_fc2) + b_fc2)\n",
    "\n",
    "n_input = 2\n",
    "n_hidden = 4\n",
    "n_hidden2 = 5\n",
    "n_output = 2\n",
    "lmd = 1e-4\n",
    "# parameters = tf.Variable(tf.concat([tf.truncated_normal([n_input * n_hidden]), tf.zeros([n_hidden]),\\\n",
    "                            # tf.truncated_normal([n_hidden * n_output]), tf.zeros([n_output])],0))\n",
    "parameters = tf.Variable(tf.concat([tf.truncated_normal([n_input * n_hidden]), tf.zeros([n_hidden]),\\\n",
    "#                                     tf.truncated_normal([n_hidden * n_hidden2]), tf.zeros([n_hidden2]),\\\n",
    "                                    tf.truncated_normal([n_hidden * n_output]), tf.zeros([n_output]),\\\n",
    "                                   ], 0))\n",
    "\n",
    "idx_from = 0 \n",
    "weights1 = tf.reshape(tf.slice(parameters, begin=[idx_from], size=[n_input*n_hidden]), [n_input, n_hidden])\n",
    "idx_from = idx_from + n_input*n_hidden\n",
    "biases1 = tf.reshape(tf.slice(parameters, begin=[idx_from], size=[n_hidden]), [n_hidden])\n",
    "hidden = tf.sigmoid(tf.matmul(x, weights1) + biases1)\n",
    "\n",
    "idx_from = idx_from + n_hidden\n",
    "weights2 = tf.reshape(tf.slice(parameters, begin=[idx_from], size=[n_hidden*n_output]), [n_hidden, n_output])\n",
    "idx_from = idx_from + n_hidden*n_output\n",
    "biases2 = tf.reshape(tf.slice(parameters, begin=[idx_from], size=[n_output]), [n_output])\n",
    "y = tf.nn.sigmoid(tf.matmul(hidden, weights2) + biases2)\n",
    "\n",
    "# idx_from = idx_from + n_hidden\n",
    "# weights2 = tf.reshape(tf.slice(parameters, begin=[idx_from], size=[n_hidden*n_hidden2]), [n_hidden, n_hidden2])\n",
    "# idx_from = idx_from + n_hidden*n_hidden2\n",
    "# biases2 = tf.reshape(tf.slice(parameters, begin=[idx_from], size=[n_hidden2]), [n_hidden2])\n",
    "# hidden2 = tf.sigmoid(tf.matmul(hidden, weights2) + biases2)\n",
    "\n",
    "# idx_from = idx_from + n_hidden2\n",
    "# weights3 = tf.reshape(tf.slice(parameters, begin=[idx_from], size=[n_hidden2*n_output]), [n_hidden2, n_output])\n",
    "# idx_from = idx_from + n_hidden2*n_output\n",
    "# biases3 = tf.reshape(tf.slice(parameters, begin=[idx_from], size=[n_output]), [n_output])\n",
    "# y = tf.nn.sigmoid(tf.matmul(hidden2, weights3) + biases3)\n",
    "\n",
    "weights = tf.concat([tf.reshape(weights1, [-1]), tf.reshape(weights2, [-1])], 0)\n",
    "regularizer = tf.nn.l2_loss(weights)\n",
    "\n",
    "los = tf.reduce_mean(tf.reduce_sum(tf.pow(y_ - y, 2), reduction_indices=[1])) #I also tried simply tf.nn.l2_loss(y_ - y)\n",
    "loss = los + lmd * regularizer\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(1.)\n",
    "grads_and_vars = optimizer.compute_gradients(loss)\n",
    "hess = tf.hessians(loss, parameters)\n",
    "train_step = optimizer.apply_gradients(grads_and_vars)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_accuracy():\n",
    "    correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    return sess.run(accuracy, feed_dict={x: data, y_: label})\n",
    "\n",
    "def get_norm_grad():\n",
    "    nng = 0.\n",
    "    for gv in grads_and_vars:\n",
    "        # print(str(sess.run(gv[0], feed_dict={x: data, y_: label})) + \" - \" + gv[1].name)\n",
    "        grad = sess.run(gv[0], feed_dict={x: data, y_: label})\n",
    "        nng += np.linalg.norm(grad[0]) ** 2\n",
    "    return np.sqrt(nng)\n",
    "\n",
    "def display(w):\n",
    "\n",
    "    idx_from = 0 \n",
    "    weights1 = np.reshape(w[idx_from: n_input*n_hidden], [n_input, n_hidden])\n",
    "    idx_from = idx_from + n_input*n_hidden\n",
    "    biases1 = np.reshape(w[idx_from: idx_from+n_hidden], [n_hidden])\n",
    "    idx_from = idx_from + n_hidden\n",
    "    weights2 = np.reshape(w[idx_from: idx_from+n_hidden*n_output], [n_hidden, n_output])\n",
    "    idx_from = idx_from + n_hidden*n_output\n",
    "    biases2 = np.reshape(w[idx_from: idx_from+n_output], [n_output])\n",
    "    print (weights1)\n",
    "    print (biases1)\n",
    "    print (weights2)\n",
    "    print (biases2)\n",
    "    \n",
    "     \n",
    "def displayH(a):\n",
    "    a = np.array(a[0])\n",
    "#     print (\"Matrix[\"+(\"%d\" %a.shape[0])+\"][\"+(\"%d\" %a.shape[1])+\"]\")\n",
    "    rows = a.shape[0]\n",
    "    cols = a.shape[1]\n",
    "    for i in range(0, rows):\n",
    "        for j in range(0, cols):\n",
    "            print(\"%0.2g \" %a[i,j], end=\"\")\n",
    "        print ()\n",
    "    print ()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199, accuracy 76.00%, loss 0.351372, nng 5.442e-09, nnw 8.203, high_eig 0.1019, low_eig -1.257e-08.\n",
      "Epoch 278, accuracy 75.00%, loss 0.343208, nng 7.974e-09, nnw 8.714, high_eig 0.1394, low_eig 7.314e-19.\n",
      "Epoch 203, accuracy 77.00%, loss 0.341544, nng 2.183e-09, nnw 7.47, high_eig 0.1882, low_eig -5.735e-12.\n",
      "Epoch 224, accuracy 78.00%, loss 0.336385, nng 5.239e-10, nnw 7.765, high_eig 0.08367, low_eig -5.719e-11.\n",
      "Epoch 205, accuracy 75.00%, loss 0.330258, nng 9.422e-09, nnw 12.54, high_eig 0.1146, low_eig -4.793e-12.\n",
      "Epoch 173, accuracy 77.00%, loss 0.359586, nng 2.669e-09, nnw 10.18, high_eig 0.09456, low_eig -2.685e-09.\n",
      "Epoch 336, accuracy 75.00%, loss 0.330258, nng 9.922e-09, nnw 12.53, high_eig 0.09776, low_eig -5.211e-11.\n",
      "Epoch 240, accuracy 75.00%, loss 0.346983, nng 7.916e-09, nnw 8.507, high_eig 0.08387, low_eig -3.324e-13.\n",
      "Epoch 206, accuracy 78.00%, loss 0.323800, nng 2.678e-09, nnw 12.45, high_eig 0.1176, low_eig -3.324e-12.\n",
      "Epoch 195, accuracy 78.00%, loss 0.336367, nng 7.858e-09, nnw 7.746, high_eig 0.1588, low_eig -4.314e-12.\n",
      "Epoch 188, accuracy 77.00%, loss 0.328224, nng 2.037e-09, nnw 9.809, high_eig 0.09604, low_eig 6.355e-05.\n",
      "Epoch 202, accuracy 78.00%, loss 0.323183, nng 9.191e-09, nnw 14.08, high_eig 0.1505, low_eig 3.067e-15.\n",
      "Epoch 170, accuracy 75.00%, loss 0.330259, nng 3.507e-09, nnw 12.56, high_eig 0.09772, low_eig -4.26e-09.\n",
      "Epoch 220, accuracy 78.00%, loss 0.336340, nng 8.935e-09, nnw 7.765, high_eig 0.08367, low_eig -1.099e-13.\n",
      "Epoch 153, accuracy 75.00%, loss 0.347108, nng 9.149e-09, nnw 8.608, high_eig 0.0839, low_eig -1.2e-09.\n",
      "Epoch 231, accuracy 75.00%, loss 0.353691, nng 9.197e-09, nnw 6.138, high_eig 0.09081, low_eig -6.231e-13.\n",
      "Epoch 239, accuracy 75.00%, loss 0.341440, nng 1.164e-10, nnw 9.834, high_eig 0.106, low_eig -2.888e-14.\n",
      "Epoch 363, accuracy 78.00%, loss 0.323800, nng 5.239e-09, nnw 12.48, high_eig 0.1176, low_eig 2.9e-18.\n",
      "Epoch 208, accuracy 75.00%, loss 0.353689, nng 8.407e-09, nnw 6.139, high_eig 0.09081, low_eig -8.513e-12.\n",
      "Epoch 131, accuracy 77.00%, loss 0.335627, nng 1.03e-09, nnw 9.808, high_eig 0.113, low_eig -1.72e-10.\n",
      "Epoch 171, accuracy 79.00%, loss 0.312298, nng 2.884e-09, nnw 16.71, high_eig 0.1372, low_eig -2.456e-10.\n",
      "Epoch 195, accuracy 78.00%, loss 0.332583, nng 7.276e-09, nnw 8.396, high_eig 0.1283, low_eig 1.705e-12.\n",
      "Epoch 183, accuracy 79.00%, loss 0.314579, nng 3.693e-09, nnw 16.85, high_eig 0.139, low_eig -0.001802.\n",
      "Epoch 260, accuracy 75.00%, loss 0.336745, nng 3.492e-09, nnw 10.22, high_eig 0.1261, low_eig -2.716e-12.\n",
      "Epoch 392, accuracy 78.00%, loss 0.323800, nng 2.561e-09, nnw 12.48, high_eig 0.1176, low_eig -1.182e-16.\n",
      "Epoch 191, accuracy 76.00%, loss 0.351368, nng 8.091e-09, nnw 8.204, high_eig 0.0937, low_eig -7.94e-11.\n",
      "Epoch 187, accuracy 78.00%, loss 0.336348, nng 0, nnw 7.787, high_eig 0.08367, low_eig -3.652e-08.\n",
      "Epoch 187, accuracy 76.00%, loss 0.351368, nng 5.267e-09, nnw 8.203, high_eig 0.09371, low_eig -1.805e-11.\n",
      "Epoch 201, accuracy 77.00%, loss 0.318942, nng 8.382e-09, nnw 15.18, high_eig 0.1608, low_eig 6.027e-05.\n",
      "Epoch 231, accuracy 75.00%, loss 0.330258, nng 2.212e-09, nnw 12.53, high_eig 0.09776, low_eig -3.892e-11.\n",
      "Epoch 228, accuracy 75.00%, loss 0.346992, nng 8.829e-09, nnw 8.507, high_eig 0.08387, low_eig -2.135e-08.\n",
      "Epoch 203, accuracy 77.00%, loss 0.335589, nng 9.909e-09, nnw 9.62, high_eig 0.1455, low_eig -1.222e-05.\n",
      "Epoch 319, accuracy 78.00%, loss 0.323800, nng 4.424e-09, nnw 12.5, high_eig 0.1176, low_eig -7.103e-13.\n",
      "Epoch 279, accuracy 75.00%, loss 0.353689, nng 9.49e-09, nnw 6.139, high_eig 0.1091, low_eig -6.937e-11.\n",
      "Epoch 230, accuracy 78.00%, loss 0.336340, nng 9.677e-09, nnw 7.766, high_eig 0.08367, low_eig 2.607e-14.\n",
      "Epoch 238, accuracy 75.00%, loss 0.353688, nng 9.604e-09, nnw 6.138, high_eig 0.1091, low_eig -5.765e-13.\n",
      "Epoch 199, accuracy 75.00%, loss 0.330258, nng 8.305e-09, nnw 12.53, high_eig 0.09776, low_eig -1.23e-09.\n",
      "Epoch 132, accuracy 75.00%, loss 0.347102, nng 7.695e-09, nnw 8.668, high_eig 0.08388, low_eig -1.636e-10.\n",
      "Epoch 364, accuracy 78.00%, loss 0.323800, nng 6.694e-09, nnw 12.48, high_eig 0.1176, low_eig -1.722e-14.\n",
      "Epoch 154, accuracy 75.00%, loss 0.330262, nng 9.444e-09, nnw 12.42, high_eig 0.09791, low_eig -7.337e-10.\n",
      "Epoch 254, accuracy 76.00%, loss 0.320315, nng 1.048e-09, nnw 14.59, high_eig 0.1039, low_eig 1.392e-15.\n",
      "Epoch 383, accuracy 75.00%, loss 0.330258, nng 9.702e-09, nnw 12.53, high_eig 0.09776, low_eig -2.37e-11.\n",
      "Epoch 252, accuracy 76.00%, loss 0.351368, nng 9.197e-09, nnw 8.203, high_eig 0.0937, low_eig -5.407e-15.\n",
      "Epoch 232, accuracy 78.00%, loss 0.336340, nng 7.16e-09, nnw 7.768, high_eig 0.08367, low_eig 4.131e-15.\n",
      "Epoch 232, accuracy 76.00%, loss 0.320315, nng 7.567e-09, nnw 14.59, high_eig 0.1039, low_eig 4.371e-15.\n",
      "Epoch 235, accuracy 75.00%, loss 0.330261, nng 1.048e-09, nnw 12.53, high_eig 0.09776, low_eig -9.437e-13.\n",
      "Epoch 322, accuracy 78.00%, loss 0.323800, nng 3.783e-10, nnw 12.48, high_eig 0.1176, low_eig 2.746e-17.\n",
      "Epoch 223, accuracy 76.00%, loss 0.351382, nng 2.794e-09, nnw 8.204, high_eig 0.0937, low_eig -3.218e-10.\n",
      "Epoch 232, accuracy 75.00%, loss 0.330258, nng 7.916e-09, nnw 12.53, high_eig 0.1029, low_eig -3.621e-15.\n",
      "Epoch 152, accuracy 75.00%, loss 0.330267, nng 8.199e-09, nnw 12.75, high_eig 0.09757, low_eig -4.859e-10.\n",
      "Epoch 265, accuracy 78.00%, loss 0.323800, nng 2.037e-10, nnw 12.48, high_eig 0.1176, low_eig 6.388e-14.\n",
      "Epoch 258, accuracy 78.00%, loss 0.336340, nng 7.276e-09, nnw 7.765, high_eig 0.08367, low_eig -1.443e-13.\n",
      "Epoch 146, accuracy 75.00%, loss 0.330265, nng 1.852e-09, nnw 12.43, high_eig 0.1149, low_eig -2.077e-10.\n",
      "Epoch 245, accuracy 75.00%, loss 0.336746, nng 9.837e-09, nnw 10.24, high_eig 0.09607, low_eig -5.598e-15.\n",
      "Epoch 115, accuracy 75.00%, loss 0.336821, nng 8.612e-10, nnw 10.35, high_eig 0.09637, low_eig -1.267e-07.\n",
      "Epoch 186, accuracy 76.00%, loss 0.351370, nng 2.503e-09, nnw 8.203, high_eig 0.0937, low_eig -3.03e-07.\n",
      "Epoch 190, accuracy 76.00%, loss 0.351369, nng 5.895e-09, nnw 8.202, high_eig 0.09369, low_eig -2.141e-09.\n",
      "Epoch 205, accuracy 76.00%, loss 0.351368, nng 3.725e-09, nnw 8.204, high_eig 0.0937, low_eig -7.466e-12.\n",
      "Epoch 204, accuracy 75.00%, loss 0.330258, nng 7.047e-09, nnw 12.53, high_eig 0.09776, low_eig -1.694e-10.\n",
      "Epoch 179, accuracy 76.00%, loss 0.320315, nng 8.01e-09, nnw 14.59, high_eig 0.1045, low_eig -3.376e-14.\n",
      "Epoch 181, accuracy 78.00%, loss 0.342056, nng 9.415e-09, nnw 7.073, high_eig 0.1024, low_eig -0.0001725.\n",
      "Epoch 238, accuracy 77.00%, loss 0.328224, nng 3.405e-09, nnw 9.808, high_eig 0.09602, low_eig 6.352e-05.\n",
      "Epoch 244, accuracy 75.00%, loss 0.343208, nng 6.636e-09, nnw 8.714, high_eig 0.117, low_eig -6.524e-13.\n",
      "Epoch 168, accuracy 78.00%, loss 0.340903, nng 4.147e-09, nnw 5.774, high_eig 0.08985, low_eig 1.205e-11.\n",
      "Epoch 365, accuracy 78.00%, loss 0.323800, nng 8.44e-10, nnw 12.48, high_eig 0.1176, low_eig -1.626e-14.\n",
      "Epoch 171, accuracy 79.00%, loss 0.312597, nng 4.735e-09, nnw 16.76, high_eig 0.1284, low_eig -1.12e-11.\n",
      "Epoch 251, accuracy 78.00%, loss 0.340901, nng 7.32e-09, nnw 5.781, high_eig 0.08985, low_eig -5.009e-14.\n",
      "Epoch 246, accuracy 75.00%, loss 0.330258, nng 3.027e-09, nnw 12.54, high_eig 0.09776, low_eig -3.661e-14.\n",
      "Epoch 241, accuracy 78.00%, loss 0.340901, nng 1.921e-09, nnw 5.781, high_eig 0.08985, low_eig -5.289e-14.\n",
      "Epoch 172, accuracy 75.00%, loss 0.353696, nng 7.185e-09, nnw 6.161, high_eig 0.1091, low_eig 2.567e-12.\n",
      "Epoch 310, accuracy 79.00%, loss 0.314341, nng 3.376e-09, nnw 10.03, high_eig 0.1941, low_eig 0.0001127.\n",
      "Epoch 257, accuracy 76.00%, loss 0.320316, nng 9.197e-09, nnw 14.59, high_eig 0.1045, low_eig -6.792e-12.\n",
      "Epoch 344, accuracy 75.00%, loss 0.353688, nng 9.948e-09, nnw 6.139, high_eig 0.09081, low_eig -6.293e-11.\n",
      "Epoch 134, accuracy 75.00%, loss 0.330422, nng 6.323e-09, nnw 12.53, high_eig 0.09765, low_eig -6.134e-08.\n",
      "Epoch 118, accuracy 75.00%, loss 0.347001, nng 8.567e-09, nnw 8.736, high_eig 0.08388, low_eig -1.858e-09.\n",
      "Epoch 238, accuracy 74.00%, loss 0.329607, nng 6.723e-09, nnw 12.84, high_eig 0.09555, low_eig -1.896e-13.\n",
      "Epoch 242, accuracy 75.00%, loss 0.330258, nng 4.424e-09, nnw 12.53, high_eig 0.09776, low_eig -1.249e-11.\n",
      "Epoch 197, accuracy 76.00%, loss 0.351368, nng 7.276e-09, nnw 8.204, high_eig 0.09369, low_eig -4.026e-11.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 267, accuracy 75.00%, loss 0.330258, nng 6.403e-09, nnw 12.53, high_eig 0.09776, low_eig 8.178e-16.\n",
      "Epoch 239, accuracy 76.00%, loss 0.351368, nng 6.869e-09, nnw 8.203, high_eig 0.0937, low_eig -6.399e-13.\n",
      "Epoch 222, accuracy 78.00%, loss 0.340903, nng 9.529e-09, nnw 5.781, high_eig 0.09913, low_eig -2.862e-10.\n",
      "Epoch 315, accuracy 75.00%, loss 0.330258, nng 4.657e-10, nnw 12.53, high_eig 0.09776, low_eig -3.509e-15.\n",
      "Epoch 252, accuracy 75.00%, loss 0.330272, nng 4.191e-09, nnw 12.53, high_eig 0.09776, low_eig -3.836e-08.\n",
      "Epoch 241, accuracy 77.00%, loss 0.318933, nng 9.793e-09, nnw 15.18, high_eig 0.1092, low_eig 8.378e-05.\n"
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "\n",
    "dic = {}\n",
    "for _ in range(100):\n",
    "\n",
    "    tf.global_variables_initializer().run()\n",
    "    flag = 0\n",
    "    for i in range(1000):\n",
    "        sess.run(train_step, feed_dict={x: data, y_: label})\n",
    "        nng = get_norm_grad()\n",
    "        if nng < 1e-8:\n",
    "            flag = 1\n",
    "            break\n",
    "\n",
    "    if flag == 1:\n",
    "        v, H, w = sess.run([loss, hess, parameters], feed_dict={x: data, y_: label})    \n",
    "        eigs = sorted(np.linalg.eigvals(H)[0])\n",
    "        print(\"Epoch {}, accuracy {:.2f}%, loss {:.6f}, nng {:.4g}, nnw {:.4g}, high_eig {:.4g}, low_eig {:.4g}.\"\\\n",
    "                    .format(i+1, get_accuracy()*100, v, nng, np.linalg.norm(w[:n_hidden]), max(eigs), min(eigs) ))\n",
    "#         display(w)\n",
    "#         displayH(H)\n",
    "        dic[int(v * 1e5)] = dic.get(int(v * 1e5), []) + [(min(eigs), w)]\n",
    "sess.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33025:\n",
      "-1.29028e-09\n",
      "[[  2.00981041e-04  -1.16835375e+01  -1.98152359e-03  -4.53153992e+00]\n",
      " [ -4.73890221e-03   3.50707793e+00   2.83185486e-03  -6.81287527e+00]]\n",
      "[-10.46237755  -5.12524939  -7.76072836  -0.88010037]\n",
      "[[  1.34084508e-01  -2.05596127e-02]\n",
      " [  2.15846109e+00  -2.15289426e+00]\n",
      " [ -1.13073774e-01  -4.63075907e-04]\n",
      " [  2.51508069e+00  -2.50468469e+00]]\n",
      "[-2.17556763  2.16860509]\n",
      "33026:\n",
      "-1.55254e-09\n",
      "[[ -2.80412380e-03  -1.16904478e+01   4.51984310e+00  -3.05295951e-04]\n",
      " [ -8.28090357e-04   3.50562286e+00   6.80034399e+00  -8.80599953e-04]]\n",
      "[ -9.25848389  -5.12742472   0.87862444 -11.90273952]\n",
      "[[-0.31488526  0.27877745]\n",
      " [ 2.15394998 -2.15380001]\n",
      " [-2.50726295  2.50705814]\n",
      " [-0.20662026  0.06780826]]\n",
      "[ 0.33813208 -0.33804536]\n",
      "33633:\n",
      "-7.01337e-12\n",
      "[[  6.16855049e+00  -1.23263846e-04  -4.37604284e+00  -1.78496468e+00]\n",
      " [  5.55536222e+00   2.20564441e-04  -1.69206452e+00   7.79499197e+00]]\n",
      "[  0.48234153  -9.76311588  -7.37112999 -12.24971104]\n",
      "[[-2.79343224  2.7932663 ]\n",
      " [ 0.03968063 -0.01291695]\n",
      " [ 2.41916394 -2.41959763]\n",
      " [ 4.33962297 -4.33938122]]\n",
      "[ 1.01446021 -1.01440656]\n",
      "34090:\n",
      "-1.03274e-09\n",
      "[[  5.46798576e-04  -2.11981702e+00   5.36526871e+00   1.25984503e-02]\n",
      " [ -9.59660392e-04   7.45365858e+00   4.79435873e+00  -7.51669693e-04]]\n",
      "[-10.89457417 -12.07284737   0.71664113  -8.65525913]\n",
      "[[-0.31993026  0.21568955]\n",
      " [ 4.31056118 -4.31975555]\n",
      " [-3.16274166  3.162709  ]\n",
      " [-0.05336861  0.04315174]]\n",
      "[ 1.37707722 -1.37700808]\n",
      "34242:\n",
      "-7.71845e-12\n",
      "[[  5.39067783e-04   1.63752527e-03   5.97727394e+00  -5.10521507e+00]\n",
      " [ -1.50970696e-03   3.06297239e-04   6.00231826e-01  -2.62632227e+00]]\n",
      "[ -7.94655752 -10.00823689  -2.76189017   0.22726521]\n",
      "[[-0.02372993 -0.00823718]\n",
      " [ 0.01509513  0.01495692]\n",
      " [ 2.82331276 -2.82175326]\n",
      " [ 4.84926653 -4.8479557 ]]\n",
      "[-3.55478311  3.55343413]\n",
      "34690:\n",
      "-5.27629e-10\n",
      "[[ -3.95772910e+00  -1.91370373e-06   2.86744162e-03   4.01692569e-01]\n",
      " [ -6.03244066e+00  -6.41144015e-06  -3.88595770e-04  -6.99501419e+00]]\n",
      "[ -0.68523216 -10.77275658  -7.74034071   0.2304142 ]\n",
      "[[  4.90870953e+00  -4.90862322e+00]\n",
      " [  3.20907457e-05   3.23919994e-05]\n",
      " [ -3.01832594e-02   4.28738492e-03]\n",
      " [ -3.01530147e+00   3.01511979e+00]]\n",
      "[-1.026016   1.0261023]\n",
      "35141:\n",
      "-6.26514e-08\n",
      "[[ -4.33276606e+00   1.94500593e-04   6.96425819e+00  -1.09597901e-02]\n",
      " [ -5.74963808e+00  -3.63342115e-04   3.71346855e+00   1.57939121e-02]]\n",
      "[-1.24889565 -8.68399525 -0.04064481 -8.6753931 ]\n",
      "[[ 1.2110517  -1.21076   ]\n",
      " [ 0.0030226   0.02593139]\n",
      " [-2.18715715  2.18718457]\n",
      " [ 0.092911   -1.01268792]]\n",
      "[ 0.31040528 -0.31045529]\n",
      "35369:\n",
      "9.19441e-12\n",
      "[[ -2.45766336e-04  -6.13942146e+00   1.82290026e-03  -4.55972593e-04]\n",
      " [  4.46218706e-04  -3.85668015e+00  -1.78032133e-04  -5.25873853e-04]]\n",
      "[ -8.45194912  -0.03266767  -9.85370731 -10.66936588]\n",
      "[[  2.88478788e-02   1.24413357e-03]\n",
      " [  3.14767218e+00  -3.14776397e+00]\n",
      " [ -1.38459662e-02  -3.13856006e-02]\n",
      " [  1.95883349e-01  -1.12080038e-01]]\n",
      "[-1.88943553  1.88946104]\n"
     ]
    }
   ],
   "source": [
    "for key in sorted(dic):\n",
    "    print (\"%s:\" % (key))\n",
    "    for e, v in dic[key]:\n",
    "        print (e)\n",
    "        display(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w0 = np.array([10,0,0,0,1,0,0,0, \n",
    "              0,0,0,0,\n",
    "              0,0,0,0,0,0,0,0, \n",
    "              0,0])\n",
    "private_init = parameters.assign(w0)\n",
    "\n",
    "idx = [1,2,3,5,6,7,\n",
    "            9,10,11] + \\\n",
    "            list(range(14,20))\n",
    "fix_coordinate = []\n",
    "for i in idx:\n",
    "    fix_coordinate.append(parameters[i].assign(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 204, accuracy 75.00%, loss 0.353688, nng 6.461e-09, nnw 6.138, high_eig 0.1378, low_eig -0.001555.\n",
      "[[ 6.1384387   0.          0.          0.        ]\n",
      " [ 3.85529733  0.          0.          0.        ]]\n",
      "[ 0.0328644  0.         0.         0.       ]\n",
      "[[-3.14847136  3.14847159]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]]\n",
      "[ 1.25850093 -1.25850058]\n",
      "Epoch 256, accuracy 75.00%, loss 0.330258, nng 2.619e-10, nnw 12.53, high_eig 0.1263+0j, low_eig -0.001666+0j.\n",
      "[[  4.52024651 -11.69125748   0.           0.        ]\n",
      " [  6.80131388   3.50514174   0.           0.        ]]\n",
      "[ 0.87811577 -5.12807369  0.          0.        ]\n",
      "[[-2.50723052  2.50723052]\n",
      " [ 2.15404177 -2.15404272]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]]\n",
      "[ 0.3379378  -0.33793768]\n",
      "Epoch 171, accuracy 75.00%, loss 0.330258, nng 5.093e-09, nnw 12.53, high_eig 0.1119, low_eig -0.001501.\n",
      "[[  4.52028894e+00  -1.16912632e+01   2.49887467e-04   0.00000000e+00]\n",
      " [  6.80136728e+00   3.50522685e+00  -8.83873668e-04   0.00000000e+00]]\n",
      "[  0.87811351  -5.128088   -15.73108006   0.        ]\n",
      "[[ -2.50726461e+00   2.50718856e+00]\n",
      " [  2.15400386e+00  -2.15406132e+00]\n",
      " [ -1.24359518e-04   4.06605104e-04]\n",
      " [  0.00000000e+00   0.00000000e+00]]\n",
      "[ 0.33794069 -0.33793011]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "dic = {}\n",
    "for _ in range(1):\n",
    "\n",
    "    tf.global_variables_initializer().run()\n",
    "    sess.run(private_init)    \n",
    "    flag = 0\n",
    "    for i in range(1000):\n",
    "        sess.run(train_step, feed_dict={x: data, y_: label})\n",
    "        for op in fix_coordinate:\n",
    "            sess.run(op)\n",
    "        nng = get_norm_grad()\n",
    "        if nng < 1e-8:\n",
    "            flag = 1\n",
    "            break\n",
    "\n",
    "    if flag == 1:\n",
    "        v, H, w = sess.run([loss, hess, parameters], feed_dict={x: data, y_: label})    \n",
    "        eigs = sorted(np.linalg.eigvals(H)[0])\n",
    "        print(\"Epoch {}, accuracy {:.2f}%, loss {:.6f}, nng {:.4g}, nnw {:.4g}, high_eig {:.4g}, low_eig {:.4g}.\"\\\n",
    "                    .format(i+1, get_accuracy()*100, v, nng, np.linalg.norm(w[:n_hidden]), max(eigs), min(eigs) ))\n",
    "        display(w)\n",
    "#         displayH(H)\n",
    "#         dic[int(v * 1e5)] = dic.get(int(v * 1e5), []) + [(min(eigs), w)]\n",
    "    \n",
    "    \n",
    "    idx = [2,3,6,7,\n",
    "            10,11] + \\\n",
    "            list(range(16,20))\n",
    "    fix_coordinate2 = []\n",
    "    for i in idx:\n",
    "        fix_coordinate2.append(parameters[i].assign(0))\n",
    "    flag = 0\n",
    "    sess.run(parameters[1].assign(1.))\n",
    "    for i in range(1000):\n",
    "        sess.run(train_step, feed_dict={x: data, y_: label})\n",
    "        for op in fix_coordinate2:\n",
    "            sess.run(op)\n",
    "        nng = get_norm_grad()\n",
    "        if nng < 1e-8:\n",
    "            flag = 1\n",
    "            break\n",
    "\n",
    "    if flag == 1:\n",
    "        v, H, w = sess.run([loss, hess, parameters], feed_dict={x: data, y_: label})    \n",
    "        eigs = sorted(np.linalg.eigvals(H)[0])\n",
    "        print(\"Epoch {}, accuracy {:.2f}%, loss {:.6f}, nng {:.4g}, nnw {:.4g}, high_eig {:.4g}, low_eig {:.4g}.\"\\\n",
    "                    .format(i+1, get_accuracy()*100, v, nng, np.linalg.norm(w[:n_hidden]), max(eigs), min(eigs) ))\n",
    "        display(w)\n",
    "        \n",
    "    idx = [3,7,\n",
    "            11] + \\\n",
    "            list(range(18,20))\n",
    "    fix_coordinate2 = []\n",
    "    for i in idx:\n",
    "        fix_coordinate2.append(parameters[i].assign(0))\n",
    "    flag = 1\n",
    "    sess.run(parameters[17].assign(.5))\n",
    "    for i in range(1000):\n",
    "        sess.run(train_step, feed_dict={x: data, y_: label})\n",
    "        for op in fix_coordinate2:\n",
    "            sess.run(op)\n",
    "        nng = get_norm_grad()\n",
    "        if nng < 1e-8:\n",
    "            flag = 1\n",
    "            break\n",
    "\n",
    "    if flag == 1:\n",
    "        v, H, w = sess.run([loss, hess, parameters], feed_dict={x: data, y_: label})    \n",
    "        eigs = sorted(np.linalg.eigvals(H)[0])\n",
    "        print(\"Epoch {}, accuracy {:.2f}%, loss {:.6f}, nng {:.4g}, nnw {:.4g}, high_eig {:.4g}, low_eig {:.4g}.\"\\\n",
    "                    .format(i+1, get_accuracy()*100, v, nng, np.linalg.norm(w[:n_hidden]), max(eigs), min(eigs) ))\n",
    "        display(w)\n",
    "         \n",
    "sess.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
